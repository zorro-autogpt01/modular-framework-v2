# docker-compose.yml
version: '3.8'

services:
  # Main Framework Container with Nginx
  framework:
    build: ./framework
    container_name: modular-framework
    ports:
      - "8080:80"
    volumes:
      - ./framework/html:/usr/share/nginx/html
      - ./framework/nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - rag-api-module
      - github-hub-module
      - llm-chat
      - browser-module
    networks:
      - app-network
    restart: unless-stopped

  # SSH Terminal Module Container
  ssh-terminal:
    build: ./modules/ssh-terminal
    container_name: ssh-terminal-module
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - PORT=3001
    networks:
      - app-network
    restart: unless-stopped

  llm-workflows:
    build: ./modules/llm-workflows
    container_name: llm-workflows-module
    environment:
      - NODE_ENV=production
      - PORT=3005
      # Tell it where your llm-chat is (service name + port on the Compose network)
      - LLM_CHAT_URL=http://llm-chat:3004/api/chat
      # Optional: serve UI under a path instead of "/"
      - BASE_PATH=/llm-workflows
      # Optional & DANGEROUS: only set to true if you want to allow host execution
      # - ALLOW_DANGEROUS=true
      # Optional: choose where workflows.json is stored (default is /app/data)
      # - DATA_DIR=/app/data
    expose:
      - "3005"
    volumes:
      # persist workflows.json
      - ./modules/llm-workflows/data:/app/data
    depends_on:
      - llm-chat
    networks:
      - app-network
    restart: unless-stopped

  github-hub-module:
    build:
      context: ./modules/github-hub
    container_name: github-hub-module
    environment:
      - PORT=3005
      # OPTIONAL: 32-byte urlsafe base64 Fernet key (keeps PAT encrypted at rest)
      # Generate once: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - GH_TOKEN_KEY=${GH_TOKEN_KEY}
      - DATA_DIR=/data
    volumes:
      - ./modules/github-hub/data:/data
    expose:
      - "3005"
    networks:
      - app-network
  llm-chat:
    build: ./modules/llm-chat
    container_name: llm-chat-module
    ports:
      - "3004:3004"
    environment:
      - NODE_ENV=production
      - PORT=3004
    networks:
      - app-network
    restart: unless-stopped

  browser-module:
    build: ./modules/browser
    container_name: browser-module
    environment:
      - PORT=3008
      - PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
      - PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser
    expose:
      - "3008"
    networks:
      - app-network
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"
    volumes:
      - ./modules/RAG/qdrant_storage:/qdrant/storage
    networks:
        - app-network
    environment:
      - QDRANT__LOG_LEVEL=INFO

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    networks:
        - app-network
    volumes:
      - ./modules/RAG/redis_data:/data

  rag-api-module:
    build: ./modules/RAG
    container_name: rag-api-module
    env_file: .env
    ports:
      - "8000:8000"
    environment:
      - QDRANT_URL=http://qdrant:6333
      - REDIS_HOST=redis
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - qdrant
      - redis
    networks:
        - app-network
    volumes:
      - ./modules/RAG/logs:/app/logs


  # Additional Module Examples (can be uncommented)
  # code-editor:
  #   build: ./modules/code-editor
  #   container_name: code-editor-module
  #   ports:
  #     - "3002:3002"
  #   networks:
  #     - app-network
  
  # git-viewer:
  #   build: ./modules/git-viewer
  #   container_name: git-viewer-module
  #   ports:
  #     - "3003:3003"
  #   networks:
  #     - app-network

networks:
  app-network:
    driver: bridge