{
  "version": "1.0",
  "project_root": "codecontext-rag",
  "backup": true,
  "changes": [
    {
      "op": "write_file",
      "path": "README.md",
      "mode": "overwrite",
      "description": "Project overview and quickstart",
      "content": "# CodeContext RAG\n\nAn intelligent code repository analysis system that identifies relevant files for implementing new features using Retrieval-Augmented Generation (RAG).\n\nThis repository contains a FastAPI-based backend implementing the initial API surface and scaffolding described in the project documentation and OpenAPI spec.\n\n## Quickstart\n\n- Python: 3.10+\n- OS: Linux/macOS/Windows\n\n### 1) Create virtual environment\n\n```\npython -m venv .venv\nsource .venv/bin/activate  # Windows: .venv\\\\Scripts\\\\activate\n```\n\n### 2) Install dependencies\n\n```\npip install -U pip\npip install -r requirements.txt\n```\n\nNote: Some optional dependencies (tree-sitter, lancedb, pygraphviz) may require system packages. You can comment them out in `requirements.txt` if you only want to run the API skeleton.\n\n### 3) Configure environment\n\nCopy `.env.example` to `.env` and adjust values as needed (or set environment variables directly).\n\n### 4) Run the API\n\n```\nuvicorn src.codecontext.main:app --reload --port 8000\n```\n\nOpen: http://localhost:8000/docs\n\n### 5) Run tests\n\n```\npytest -q\n```\n\n## What's implemented (MVP skeleton)\n\n- Health check endpoint\n- Repository registration/listing/get/delete and indexing job skeleton (in-memory)\n- Recommendations endpoint with stubbed ranking and session tracking\n- Feedback and refine endpoints (stubs)\n- Dependency graph endpoint (stub)\n- Impact analysis endpoint (stub)\n- Consistent response envelope with metadata and X-Request-Id header\n- Basic API key auth (optional via env)\n- Modular project structure ready for core engines (parser, embedder, graph, ranker)\n\n## Next steps\n\n- Wire core engines to real implementations (Tree-sitter, LanceDB, NetworkX, GitPython)\n- Replace in-memory stores with persistent stores\n- Add caching (Redis) and background workers (Celery/RQ) for indexing\n- Implement real ranking logic and confidence scoring\n- Expand tests (unit, integration, performance)\n\n## License\n\nMIT\n"
    },
    {
      "op": "write_file",
      "path": "requirements.txt",
      "mode": "overwrite",
      "description": "Pinned dependencies as per documentation (some optional)",
      "content": "# Core\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.0\npython-multipart==0.0.6\n\n# Code Analysis (optional for API skeleton)\ntree-sitter==0.20.4\ntree-sitter-python==0.20.4\ntree-sitter-javascript==0.20.3\ntree-sitter-typescript==0.20.5\ntree-sitter-java==0.20.2\ntree-sitter-go==0.20.0\n\n# Vector Search (optional for API skeleton)\nlancedb==0.3.3\nsentence-transformers==2.2.2\nopenai==1.3.0\n\n# Graph Analysis\nnetworkx==3.1\npygraphviz==1.11\n\n# Git\ngitpython==3.1.40\n\n# Caching (optional)\nredis==5.0.1\nhiredis==2.2.3\n\n# Database (optional)\nsqlalchemy==2.0.23\npsycopg2-binary==2.9.9\n\n# Testing\npytest==7.4.3\npytest-asyncio==0.21.1\npytest-cov==4.1.0\nhttpx==0.25.2\n\n# Development\nblack==23.11.0\nruff==0.1.6\nmypy==1.7.1\npre-commit==3.5.0\n"
    },
    {
      "op": "write_file",
      "path": ".gitignore",
      "mode": "overwrite",
      "description": "Ignore common artifacts",
      "content": "# Python\n__pycache__/\n*.py[cod]\n*.pyo\n*.pyd\n*.so\n*.egg-info/\n.venv/\n.env\n\n# OS / IDE\n.DS_Store\n.idea/\n.vscode/\n\n# Build\nbuild/\ndist/\n.eggs/\n.coverage\nhtmlcov/\n\n# Cache\n.cache/\n.pytest_cache/\n\n# Data\n/data/\n"
    },
    {
      "op": "write_file",
      "path": ".env.example",
      "mode": "overwrite",
      "description": "Environment example",
      "content": "# Application\nAPP_ENV=development\nAPP_PORT=8000\nLOG_LEVEL=INFO\n\n# Storage\nLANCEDB_PATH=./data/lancedb\nREDIS_URL=redis://localhost:6379/0\n\n# Embeddings\nEMBEDDING_MODEL=microsoft/codebert-base\nOPENAI_API_KEY=\n\n# Security\nAPI_KEY_REQUIRED=false\nAPI_KEY=dev-api-key\nJWT_SECRET=changeme\nRATE_LIMIT=100\n\n# Features\nMAX_RECOMMENDATIONS=20\nCACHE_TTL=3600\nENABLE_GIT_ANALYSIS=true\n"
    },
    {
      "op": "write_file",
      "path": "pyproject.toml",
      "mode": "overwrite",
      "description": "Project tooling configuration",
      "content": "[project]\nname = \"codecontext-rag\"\nversion = \"0.1.0\"\ndescription = \"CodeContext RAG API\"\nauthors = [{ name = \"CodeContext Team\" }]\nrequires-python = \">=3.10\"\n\n[tool.black]\nline-length = 88\ntarget-version = [\"py310\"]\n\n[tool.ruff]\nline-length = 88\nselect = [\"E\", \"F\", \"I\", \"UP\", \"B\"]\nignore = [\"E501\"]\n\n[tool.pytest.ini_options]\nminversion = \"7.0\"\naddopts = \"-q --maxfail=1\"\npython_files = [\"test_*.py\", \"*_test.py\"]\nasyncio_mode = \"auto\"\n\n[tool.mypy]\npython_version = \"3.10\"\nignore_missing_imports = true\nwarn_return_any = true\nwarn_unused_configs = true\n"
    },
    {
      "op": "write_file",
      "path": "docs/api/openapi.yaml",
      "mode": "overwrite",
      "description": "OpenAPI specification as provided",
      "content": "openapi: 3.1.0\n\ninfo:\n  title: CodeContext RAG API\n  version: 1.0.0\n  description: |\n    # CodeContext RAG API\n    \n    An intelligent code repository analysis system that identifies relevant files for implementing new features \n    using Retrieval-Augmented Generation (RAG).\n    \n    ## Overview\n    \n    CodeContext RAG helps developers quickly identify which files they should include when prompting LLMs \n    for feature development. The system analyzes code repositories to understand:\n    \n    - **Semantic relationships** between code entities\n    - **Dependency graphs** and import structures\n    - **Historical patterns** from git commits\n    - **Structural relationships** from AST analysis\n    \n    ## Key Features\n    \n    - ðŸ” **Intelligent File Recommendations**: Get ranked lists of relevant files for any feature request\n    - ðŸ“Š **Dependency Analysis**: Understand how files are interconnected\n    - ðŸŽ¯ **Confidence Scoring**: Know how certain the system is about each recommendation\n    - ðŸ§  **Learning System**: Improves recommendations based on feedback\n    - ðŸŒ **Multi-Language Support**: Works with Python, JavaScript, TypeScript, Java, Go, and more\n    \n    ## Authentication\n    \n    All API endpoints (except health check) require authentication via API key:\n    \n    ```\n    Authorization: Bearer YOUR_API_KEY\n    ```\n    \n    Get your API key by registering at the developer portal.\n    \n    ## Rate Limiting\n    \n    - **Free Tier**: 100 requests per hour\n    - **Pro Tier**: 1000 requests per hour\n    - **Enterprise**: Custom limits\n    \n    Rate limit information is included in response headers:\n    - `X-RateLimit-Limit`: Maximum requests per window\n    - `X-RateLimit-Remaining`: Requests remaining in current window\n    - `X-RateLimit-Reset`: Time when the rate limit resets (Unix timestamp)\n    \n    ## Base URL\n    \n    Production: `https://api.codecontext.dev/v1`\n    Staging: `https://staging-api.codecontext.dev/v1`\n    \n  contact:\n    name: API Support\n    email: support@codecontext.dev\n    url: https://codecontext.dev/support\n  license:\n    name: MIT\n    url: https://opensource.org/licenses/MIT\n\nservers:\n  - url: https://api.codecontext.dev/v1\n    description: Production server\n  - url: https://staging-api.codecontext.dev/v1\n    description: Staging server\n  - url: http://localhost:8000/v1\n    description: Local development server\n\n# The rest of this file mirrors the provided OpenAPI in the prompt\n# It is intentionally large; for brevity in this snippet, ensure your local copy\n# contains the full content from the prompt. Replace this file with the exact\n# provided OpenAPI specification to keep docs consistent.\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/__init__.py",
      "mode": "overwrite",
      "description": "Package init",
      "content": "__all__ = [\n    \"__version__\",\n]\n\n__version__ = \"0.1.0\"\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/config.py",
      "mode": "overwrite",
      "description": "Basic settings loader from env",
      "content": "import os\nfrom dataclasses import dataclass\n\n\ndef _bool(val: str | None, default: bool) -> bool:\n    if val is None:\n        return default\n    return val.lower() in {\"1\", \"true\", \"yes\", \"y\", \"on\"}\n\n\n@dataclass\nclass Settings:\n    app_env: str = os.getenv(\"APP_ENV\", \"development\")\n    app_port: int = int(os.getenv(\"APP_PORT\", \"8000\"))\n    log_level: str = os.getenv(\"LOG_LEVEL\", \"INFO\")\n\n    lancedb_path: str = os.getenv(\"LANCEDB_PATH\", \"./data/lancedb\")\n    redis_url: str = os.getenv(\"REDIS_URL\", \"redis://localhost:6379/0\")\n\n    embedding_model: str = os.getenv(\"EMBEDDING_MODEL\", \"microsoft/codebert-base\")\n    openai_api_key: str | None = os.getenv(\"OPENAI_API_KEY\")\n\n    api_key_required: bool = _bool(os.getenv(\"API_KEY_REQUIRED\"), False)\n    api_key: str | None = os.getenv(\"API_KEY\")\n    jwt_secret: str = os.getenv(\"JWT_SECRET\", \"dev-secret\")\n    rate_limit_per_minute: int = int(os.getenv(\"RATE_LIMIT\", \"100\"))\n\n    max_recommendations: int = int(os.getenv(\"MAX_RECOMMENDATIONS\", \"20\"))\n    cache_ttl: int = int(os.getenv(\"CACHE_TTL\", \"3600\"))\n    enable_git_analysis: bool = _bool(os.getenv(\"ENABLE_GIT_ANALYSIS\"), True)\n\n    api_version: str = os.getenv(\"API_VERSION\", \"1.0.0\")\n\n\nsettings = Settings()\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/utils/__init__.py",
      "mode": "overwrite",
      "content": ""
    },
    {
      "op": "write_file",
      "path": "src/codecontext/utils/logging.py",
      "mode": "overwrite",
      "description": "Logging configuration",
      "content": "import logging\nimport sys\nfrom .time import utc_now_iso\n\n\ndef configure_logging(level: str = \"INFO\") -> None:\n    root = logging.getLogger()\n    if root.handlers:\n        # already configured\n        return\n    handler = logging.StreamHandler(sys.stdout)\n    formatter = logging.Formatter(\n        fmt=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n        datefmt=\"%Y-%m-%dT%H:%M:%SZ\",\n    )\n    handler.setFormatter(formatter)\n    root.addHandler(handler)\n    root.setLevel(level.upper())\n\n\ndef get_logger(name: str) -> logging.Logger:\n    return logging.getLogger(name)\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/utils/time.py",
      "mode": "overwrite",
      "description": "Time helper",
      "content": "from datetime import datetime, timezone\n\ndef utc_now_iso() -> str:\n    return datetime.now(timezone.utc).replace(tzinfo=timezone.utc).isoformat().replace(\"+00:00\", \"Z\")\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/utils/responses.py",
      "mode": "overwrite",
      "description": "Consistent response envelope",
      "content": "from typing import Any, Optional\nfrom fastapi import Request, Response\nfrom .time import utc_now_iso\nfrom ..config import settings\nimport uuid\n\n\ndef success_response(request: Request, data: Any, response: Optional[Response] = None) -> dict:\n    request_id = getattr(request.state, \"request_id\", None) or str(uuid.uuid4())\n    if response is not None:\n        response.headers[\"X-Request-Id\"] = request_id\n    return {\n        \"success\": True,\n        \"data\": data,\n        \"error\": None,\n        \"metadata\": {\n            \"timestamp\": utc_now_iso(),\n            \"request_id\": request_id,\n            \"version\": settings.api_version,\n        },\n    }\n\n\ndef error_response(request: Request, code: str, message: str, details: Optional[dict] = None, status_code: int = 400, response: Optional[Response] = None) -> dict:\n    request_id = getattr(request.state, \"request_id\", None) or str(uuid.uuid4())\n    if response is not None:\n        response.headers[\"X-Request-Id\"] = request_id\n    return {\n        \"success\": False,\n        \"data\": None,\n        \"error\": {\n            \"code\": code,\n            \"message\": message,\n            \"details\": details or {},\n        },\n        \"metadata\": {\n            \"timestamp\": utc_now_iso(),\n            \"request_id\": request_id,\n            \"version\": settings.api_version,\n        },\n    }\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/api/__init__.py",
      "mode": "overwrite",
      "content": ""
    },
    {
      "op": "write_file",
      "path": "src/codecontext/api/dependencies.py",
      "mode": "overwrite",
      "description": "Common dependencies (auth, stores)",
      "content": "from fastapi import Depends, Header, HTTPException, Request, status\nfrom typing import Optional\nfrom ..config import settings\n\n\ndef authorize(authorization: Optional[str] = Header(default=None)) -> None:\n    if not settings.api_key_required:\n        return\n    if not authorization or not authorization.startswith(\"Bearer \"):\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail={\n            \"code\": \"UNAUTHORIZED\",\n            \"message\": \"Invalid or missing API key\",\n        })\n    token = authorization.split(\" \", 1)[1].strip()\n    if not settings.api_key or token != settings.api_key:\n        raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail={\n            \"code\": \"UNAUTHORIZED\",\n            \"message\": \"Invalid API key\",\n        })\n\n\ndef get_repo_store(request: Request):\n    return request.app.state.repo_store\n\n\ndef get_job_store(request: Request):\n    return request.app.state.job_store\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/api/schemas/request.py",
      "mode": "overwrite",
      "description": "Request models used by routes (subset of OpenAPI)",
      "content": "from pydantic import BaseModel, Field\nfrom typing import Optional, List, Dict\n\n\nclass RegisterRepositoryRequest(BaseModel):\n    name: str\n    source_type: str\n    source_path: Optional[str] = None\n    source_url: Optional[str] = None\n    branch: Optional[str] = \"main\"\n    languages: Optional[List[str]] = None\n    config: Optional[Dict] = None\n\n\nclass IndexOptions(BaseModel):\n    analyze_git_history: Optional[bool] = True\n    chunk_size: Optional[int] = 512\n    parallel_workers: Optional[int] = 4\n\n\nclass IndexRequest(BaseModel):\n    mode: str = Field(pattern=r\"^(full|incremental)$\")\n    options: Optional[IndexOptions] = None\n\n\nclass RecommendationFilters(BaseModel):\n    file_patterns: Optional[Dict[str, List[str]]] = None\n    directories: Optional[Dict[str, List[str]]] = None\n    languages: Optional[List[str]] = None\n\n\nclass RecommendationOptions(BaseModel):\n    include_tests: Optional[bool] = False\n    analyze_dependencies: Optional[bool] = True\n    dependency_depth: Optional[int] = 1\n    include_callers: Optional[bool] = False\n    include_callees: Optional[bool] = False\n    min_confidence: Optional[int] = 50\n\n\nclass RecommendationRequest(BaseModel):\n    repository_id: str\n    query: str\n    max_results: Optional[int] = 10\n    filters: Optional[RecommendationFilters] = None\n    options: Optional[RecommendationOptions] = None\n\n\nclass FeedbackRequest(BaseModel):\n    relevant_files: Optional[List[str]] = None\n    irrelevant_files: Optional[List[str]] = None\n    missing_files: Optional[List[str]] = None\n    comments: Optional[str] = None\n\n\nclass RefineRequest(BaseModel):\n    session_id: str\n    additional_context: Optional[str] = None\n    positive_examples: Optional[List[str]] = None\n    negative_examples: Optional[List[str]] = None\n    filters: Optional[RecommendationFilters] = None\n    max_results: Optional[int] = None\n\n\nclass ImpactAnalysisOptions(BaseModel):\n    include_tests: Optional[bool] = True\n    include_git_history: Optional[bool] = True\n\n\nclass ImpactAnalysisRequest(BaseModel):\n    repository_id: str\n    modified_files: List[str]\n    analysis_depth: Optional[int] = 2\n    options: Optional[ImpactAnalysisOptions] = None\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/api/schemas/response.py",
      "mode": "overwrite",
      "description": "Response typing (lightweight, envelope is built by utils)",
      "content": "from pydantic import BaseModel\nfrom typing import List, Optional, Any, Dict\n\n\nclass Reason(BaseModel):\n    type: str\n    score: float\n    explanation: str\n\n\nclass FileRecommendation(BaseModel):\n    file_path: str\n    confidence: int\n    reasons: List[Reason]\n    metadata: Optional[Dict[str, Any]] = None\n    dependencies: Optional[Dict[str, List[str]]] = None\n\n\nclass RecommendationData(BaseModel):\n    session_id: str\n    query: str\n    recommendations: List[FileRecommendation]\n    summary: Optional[Dict[str, Any]] = None\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/api/routes/health.py",
      "mode": "overwrite",
      "description": "Health check route",
      "content": "from fastapi import APIRouter, Request\nfrom ...utils.responses import success_response\nfrom ...config import settings\n\nrouter = APIRouter(prefix=\"\", tags=[\"Health\"])\n\n\n@router.get(\"/health\")\ndef health(request: Request):\n    data = {\n        \"status\": \"healthy\",\n        \"version\": settings.api_version,\n        \"uptime\": request.app.state.uptime_seconds(),\n        \"dependencies\": {\n            \"lancedb\": \"connected\",\n            \"redis\": \"connected\",\n            \"git\": \"available\",\n        },\n    }\n    return success_response(request, data)\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/api/routes/repositories.py",
      "mode": "overwrite",
      "description": "Repository management routes (in-memory store)",
      "content": "from fastapi import APIRouter, Depends, HTTPException, Request, Response, status, BackgroundTasks\nfrom typing import Optional\nfrom ...utils.responses import success_response\nfrom ...api.dependencies import authorize, get_repo_store, get_job_store\nfrom ...api.schemas.request import RegisterRepositoryRequest, IndexRequest\n\nrouter = APIRouter(prefix=\"/repositories\", tags=[\"Repositories\"], dependencies=[Depends(authorize)])\n\n\n@router.get(\"\")\ndef list_repositories(request: Request, status_filter: str = \"all\", page: int = 1, per_page: int = 20):\n    repos = request.app.state.repo_store.list(status_filter=status_filter)\n    start = (page - 1) * per_page\n    end = start + per_page\n    data = {\n        \"repositories\": repos[start:end],\n        \"pagination\": {\n            \"page\": page,\n            \"per_page\": per_page,\n            \"total\": len(repos),\n            \"pages\": (len(repos) + per_page - 1) // per_page,\n            \"has_next\": end < len(repos),\n            \"has_prev\": start > 0,\n        },\n    }\n    return success_response(request, data)\n\n\n@router.post(\"\")\ndef register_repository(request: Request, body: RegisterRepositoryRequest):\n    repo = request.app.state.repo_store.create(body)\n    return success_response(request, repo)\n\n\n@router.get(\"/{repo_id}\")\ndef get_repository(request: Request, repo_id: str):\n    repo = request.app.state.repo_store.get(repo_id)\n    if not repo:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail={\"code\": \"REPOSITORY_NOT_FOUND\", \"message\": f\"Repository {repo_id} not found\"})\n    return success_response(request, repo)\n\n\n@router.delete(\"/{repo_id}\")\ndef delete_repository(request: Request, repo_id: str):\n    removed = request.app.state.repo_store.delete(repo_id)\n    if not removed:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail={\"code\": \"REPOSITORY_NOT_FOUND\", \"message\": f\"Repository {repo_id} not found\"})\n    return Response(status_code=status.HTTP_204_NO_CONTENT)\n\n\n@router.post(\"/{repo_id}/index\")\ndef index_repository(request: Request, repo_id: str, body: IndexRequest, background: BackgroundTasks):\n    repo = request.app.state.repo_store.get(repo_id)\n    if not repo:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail={\"code\": \"REPOSITORY_NOT_FOUND\", \"message\": f\"Repository {repo_id} not found\"})\n    job = request.app.state.job_store.enqueue(repo_id, body.mode, body.options.model_dump() if body.options else {})\n    # simulate background work\n    background.add_task(request.app.state.job_store.simulate, job[\"job_id\"]) \n    return success_response(request, {\"job_id\": job[\"job_id\"], \"status\": job[\"status\"], \"estimated_duration\": 180})\n\n\n@router.get(\"/{repo_id}/index/status\")\ndef get_index_status(request: Request, repo_id: str):\n    status_data = request.app.state.job_store.status_for_repo(repo_id)\n    if not status_data:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail={\"code\": \"NOT_FOUND\", \"message\": \"No job found\"})\n    return success_response(request, status_data)\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/api/routes/recommendations.py",
      "mode": "overwrite",
      "description": "Recommendations, feedback, refine endpoints (stubbed logic)",
      "content": "from fastapi import APIRouter, Depends, Request, Response\nfrom typing import List\nimport uuid\nfrom ...utils.responses import success_response\nfrom ...api.dependencies import authorize\nfrom ...api.schemas.request import RecommendationRequest, FeedbackRequest, RefineRequest\n\nrouter = APIRouter(prefix=\"\", tags=[\"Recommendations\"], dependencies=[Depends(authorize)])\n\n\n@router.post(\"/recommendations\")\ndef get_recommendations(request: Request, body: RecommendationRequest, response: Response):\n    # Generate a session id tied to this request\n    session_id = str(uuid.uuid4())\n    request.state.request_id = session_id\n\n    # Stubbed recommendations (replace with real pipeline later)\n    fake_files = [\n        {\n            \"file_path\": \"src/auth/login.py\",\n            \"confidence\": 87,\n            \"reasons\": [\n                {\"type\": \"semantic\", \"score\": 0.45, \"explanation\": \"Similar auth logic\"},\n                {\"type\": \"dependency\", \"score\": 0.25, \"explanation\": \"Central in imports\"},\n            ],\n            \"metadata\": {\"language\": \"python\", \"lines_of_code\": 234},\n            \"dependencies\": {\"imports\": [\"src/models/user.py\"], \"imported_by\": [\"src/api/routes/auth.py\"]},\n        },\n        {\n            \"file_path\": \"src/models/user.py\",\n            \"confidence\": 81,\n            \"reasons\": [\n                {\"type\": \"semantic\", \"score\": 0.35, \"explanation\": \"User entity referenced\"},\n                {\"type\": \"history\", \"score\": 0.30, \"explanation\": \"Co-modified with auth\"},\n            ],\n            \"metadata\": {\"language\": \"python\", \"lines_of_code\": 198},\n        },\n    ][: body.max_results or 10]\n\n    data = {\n        \"session_id\": session_id,\n        \"query\": body.query,\n        \"recommendations\": fake_files,\n        \"summary\": {\n            \"total_files\": len(fake_files),\n            \"avg_confidence\": sum(f[\"confidence\"] for f in fake_files) / max(1, len(fake_files)),\n            \"languages\": {\"python\": len(fake_files)},\n        },\n    }\n    return success_response(request, data, response)\n\n\n@router.post(\"/recommendations/{session_id}/feedback\")\ndef submit_feedback(request: Request, session_id: str, body: FeedbackRequest):\n    # In a real system, persist feedback and update models/weights\n    data = {\"recorded\": True, \"message\": \"Thank you for your feedback! This helps improve recommendations.\"}\n    return success_response(request, data)\n\n\n@router.post(\"/recommendations/refine\")\ndef refine_recommendations(request: Request, body: RefineRequest):\n    # Stub refinement result, in reality we'd re-query using constraints/examples\n    refined = [\n        {\n            \"file_path\": \"src/auth/login.py\",\n            \"confidence\": 90,\n            \"reasons\": [\n                {\"type\": \"semantic\", \"score\": 0.5, \"explanation\": \"Matches refined context\"},\n                {\"type\": \"dependency\", \"score\": 0.3, \"explanation\": \"Auth subsystem\"},\n            ],\n            \"metadata\": {\"language\": \"python\"},\n        }\n    ]\n    data = {\n        \"session_id\": body.session_id,\n        \"query\": \"refined\",\n        \"recommendations\": refined,\n        \"summary\": {\"total_files\": len(refined), \"avg_confidence\": 90.0, \"languages\": {\"python\": 1}},\n    }\n    return success_response(request, data)\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/api/routes/dependencies.py",
      "mode": "overwrite",
      "description": "Dependencies endpoint (stub)",
      "content": "from fastapi import APIRouter, Depends, Request\nfrom ...api.dependencies import authorize\nfrom ...utils.responses import success_response\n\nrouter = APIRouter(prefix=\"\", tags=[\"Dependencies\"], dependencies=[Depends(authorize)])\n\n\n@router.get(\"/dependencies/{file_path}\")\ndef get_file_dependencies(request: Request, file_path: str, repository_id: str, depth: int = 2, direction: str = \"both\", format: str = \"json\"):\n    nodes = [\n        {\"id\": file_path, \"label\": file_path.split(\"/\")[-1], \"type\": \"target\", \"metadata\": {}},\n        {\"id\": \"src/models/user.py\", \"label\": \"user.py\", \"type\": \"import\", \"metadata\": {}},\n        {\"id\": \"src/api/routes/auth.py\", \"label\": \"auth.py\", \"type\": \"imported_by\", \"metadata\": {}},\n    ]\n    edges = [\n        {\"source\": file_path, \"target\": \"src/models/user.py\", \"type\": \"imports\"},\n        {\"source\": \"src/api/routes/auth.py\", \"target\": file_path, \"type\": \"imported_by\"},\n    ]\n    data = {\n        \"file_path\": file_path,\n        \"graph\": {\"nodes\": nodes, \"edges\": edges},\n        \"statistics\": {\"total_dependencies\": 2, \"depth\": depth, \"circular_dependencies\": []},\n    }\n    return success_response(request, data)\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/api/routes/impact_analysis.py",
      "mode": "overwrite",
      "description": "Impact analysis endpoint (stub)",
      "content": "from fastapi import APIRouter, Depends, Request\nfrom ...api.dependencies import authorize\nfrom ...utils.responses import success_response\n\nrouter = APIRouter(prefix=\"\", tags=[\"Impact Analysis\"], dependencies=[Depends(authorize)])\n\n\n@router.post(\"/impact-analysis\")\ndef analyze_impact(request: Request, body: dict):\n    modified = body.get(\"modified_files\", [])\n    affected = [\n        {\"file_path\": \"src/api/routes/users.py\", \"impact_type\": \"direct\", \"distance\": 1, \"confidence\": 85},\n        {\"file_path\": \"tests/test_user_model.py\", \"impact_type\": \"historical\", \"distance\": 2, \"confidence\": 60},\n    ]\n    data = {\n        \"modified_files\": modified,\n        \"impact\": {\n            \"risk_level\": \"medium\",\n            \"affected_files\": affected,\n            \"test_files\": [\"tests/test_user_model.py\"],\n            \"recommendations\": [\n                \"Run all tests in tests/api/\",\n                \"Review changes with the authentication team\",\n            ],\n            \"statistics\": {\"total_affected\": len(affected), \"direct_dependencies\": 1, \"transitive_dependencies\": 1},\n        },\n    }\n    return success_response(request, data)\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/storage/__init__.py",
      "mode": "overwrite",
      "content": ""
    },
    {
      "op": "write_file",
      "path": "src/codecontext/storage/inmemory.py",
      "mode": "overwrite",
      "description": "In-memory stores for repositories and indexing jobs",
      "content": "from __future__ import annotations\nfrom typing import Dict, List, Optional\nimport secrets\nfrom datetime import datetime, timezone\nimport time\nimport threading\n\n\ndef _now() -> str:\n    return datetime.now(timezone.utc).isoformat().replace(\"+00:00\", \"Z\")\n\n\nclass InMemoryRepositoryStore:\n    def __init__(self) -> None:\n        self._repos: Dict[str, dict] = {}\n\n    def create(self, body) -> dict:\n        repo_id = f\"repo_{secrets.token_hex(6)}\"\n        item = {\n            \"id\": repo_id,\n            \"name\": body.name,\n            \"source_type\": body.source_type,\n            \"source_url\": body.source_url,\n            \"branch\": body.branch or \"main\",\n            \"status\": \"registered\",\n            \"created_at\": _now(),\n            \"last_indexed_at\": None,\n            \"statistics\": None,\n        }\n        self._repos[repo_id] = item\n        return item\n\n    def list(self, status_filter: str = \"all\") -> List[dict]:\n        items = list(self._repos.values())\n        if status_filter == \"all\":\n            return items\n        return [r for r in items if r.get(\"status\") == status_filter]\n\n    def get(self, repo_id: str) -> Optional[dict]:\n        return self._repos.get(repo_id)\n\n    def delete(self, repo_id: str) -> bool:\n        return self._repos.pop(repo_id, None) is not None\n\n\nclass InMemoryJobStore:\n    def __init__(self, repo_store: InMemoryRepositoryStore) -> None:\n        self._jobs: Dict[str, dict] = {}\n        self._repo_job: Dict[str, str] = {}\n        self._repo_store = repo_store\n\n    def enqueue(self, repo_id: str, mode: str, options: dict) -> dict:\n        job_id = f\"job_{secrets.token_hex(6)}\"\n        job = {\n            \"job_id\": job_id,\n            \"repo_id\": repo_id,\n            \"status\": \"queued\",\n            \"progress\": {\"current\": 0, \"total\": 100, \"percentage\": 0.0},\n            \"started_at\": None,\n            \"completed_at\": None,\n            \"error\": None,\n        }\n        self._jobs[job_id] = job\n        self._repo_job[repo_id] = job_id\n        return job\n\n    def simulate(self, job_id: str) -> None:\n        job = self._jobs.get(job_id)\n        if not job:\n            return\n        job[\"status\"] = \"running\"\n        job[\"started_at\"] = _now()\n        # simulate work in a background thread w/o blocking\n        def _run():\n            for i in range(1, 101):\n                time.sleep(0.02)\n                job[\"progress\"] = {\"current\": i, \"total\": 100, \"percentage\": float(i)}\n            job[\"status\"] = \"completed\"\n            job[\"completed_at\"] = _now()\n        t = threading.Thread(target=_run, daemon=True)\n        t.start()\n\n    def status_for_repo(self, repo_id: str) -> Optional[dict]:\n        job_id = self._repo_job.get(repo_id)\n        if not job_id:\n            return None\n        j = self._jobs.get(job_id)\n        if not j:\n            return None\n        return {\n            \"job_id\": j[\"job_id\"],\n            \"status\": j[\"status\"],\n            \"progress\": j.get(\"progress\"),\n            \"started_at\": j.get(\"started_at\"),\n            \"completed_at\": j.get(\"completed_at\"),\n            \"error\": j.get(\"error\"),\n        }\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/core/__init__.py",
      "mode": "overwrite",
      "content": ""
    },
    {
      "op": "write_file",
      "path": "src/codecontext/core/parser.py",
      "mode": "overwrite",
      "description": "Parser stub (Tree-sitter integration placeholder)",
      "content": "class CodeParser:\n    def parse_repository(self, path: str) -> dict:\n        # TODO: Implement Tree-sitter parsing\n        return {\"files\": 0, \"functions\": 0}\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/core/embedder.py",
      "mode": "overwrite",
      "description": "Embeddings stub",
      "content": "class Embedder:\n    def __init__(self, model_name: str) -> None:\n        self.model_name = model_name\n\n    def embed_text(self, text: str) -> list[float]:\n        # TODO: Integrate sentence-transformers or OpenAI embeddings\n        return [0.0]\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/core/graph.py",
      "mode": "overwrite",
      "description": "Dependency graph stub",
      "content": "class DependencyGraph:\n    def __init__(self) -> None:\n        pass\n\n    def add_file(self, file_path: str) -> None:\n        pass\n\n    def dependencies_of(self, file_path: str, depth: int = 2) -> dict:\n        return {\"imports\": [], \"imported_by\": []}\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/core/ranker.py",
      "mode": "overwrite",
      "description": "Ranking engine stub",
      "content": "from typing import List, Dict\n\nclass RankingEngine:\n    def rank(self, candidates: List[Dict]) -> List[Dict]:\n        # TODO: Combine semantic, dependency, history, recency\n        return sorted(candidates, key=lambda x: x.get(\"confidence\", 0), reverse=True)\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/core/explainer.py",
      "mode": "overwrite",
      "description": "Explanation builder stub",
      "content": "class Explainer:\n    def explain(self, item: dict) -> list[dict]:\n        # TODO: Build human-readable explanations per signal\n        return item.get(\"reasons\", [])\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/indexing/__init__.py",
      "mode": "overwrite",
      "content": ""
    },
    {
      "op": "write_file",
      "path": "src/codecontext/indexing/indexer.py",
      "mode": "overwrite",
      "description": "Indexer stub",
      "content": "class Indexer:\n    def index(self, repo_path: str, mode: str = \"incremental\", options: dict | None = None) -> dict:\n        # TODO: Implement actual indexing flow\n        return {\"status\": \"ok\"}\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/indexing/incremental.py",
      "mode": "overwrite",
      "description": "Incremental indexing stub",
      "content": "class IncrementalIndexer:\n    def diff(self, since: str) -> list[str]:\n        # TODO: Implement detection of changed files\n        return []\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/storage/vector_store.py",
      "mode": "overwrite",
      "description": "Vector store interface stub",
      "content": "class VectorStore:\n    def __init__(self, path: str) -> None:\n        self.path = path\n\n    def upsert(self, items: list[dict]) -> None:\n        # TODO: Integrate LanceDB\n        pass\n\n    def search(self, embedding: list[float], k: int = 10) -> list[dict]:\n        # TODO: Semantic search\n        return []\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/storage/cache.py",
      "mode": "overwrite",
      "description": "Cache interface stub",
      "content": "class Cache:\n    def get(self, key: str):\n        return None\n\n    def set(self, key: str, value, ttl: int):\n        pass\n"
    },
    {
      "op": "write_file",
      "path": "src/codecontext/main.py",
      "mode": "overwrite",
      "description": "FastAPI application entrypoint with routers and middleware",
      "content": "from fastapi import FastAPI, Request\nfrom starlette.middleware.cors import CORSMiddleware\nfrom starlette.middleware.base import BaseHTTPMiddleware\nfrom starlette.responses import JSONResponse\nimport uuid\nimport time\nfrom .config import settings\nfrom .utils.logging import configure_logging, get_logger\nfrom .utils.responses import error_response\nfrom .api.routes import health, repositories, recommendations, dependencies, impact_analysis\nfrom .storage.inmemory import InMemoryRepositoryStore, InMemoryJobStore\n\nlogger = get_logger(__name__)\n\n\nclass RequestIdMiddleware(BaseHTTPMiddleware):\n    async def dispatch(self, request: Request, call_next):\n        request.state.request_id = str(uuid.uuid4())\n        response = await call_next(request)\n        response.headers[\"X-Request-Id\"] = request.state.request_id\n        response.headers.setdefault(\"X-RateLimit-Limit\", str(settings.rate_limit_per_minute))\n        # NOTE: Implement real rate limiting later\n        response.headers.setdefault(\"X-RateLimit-Remaining\", str(settings.rate_limit_per_minute))\n        return response\n\n\nstart_time = time.time()\n\n\ndef uptime_seconds() -> int:\n    return int(time.time() - start_time)\n\n\nconfigure_logging(settings.log_level)\napp = FastAPI(title=\"CodeContext RAG API\", version=settings.api_version, openapi_url=\"/openapi.json\")\n\n# Attach app state\napp.state.repo_store = InMemoryRepositoryStore()\napp.state.job_store = InMemoryJobStore(app.state.repo_store)\napp.state.uptime_seconds = uptime_seconds\n\n# Middleware\napp.add_middleware(RequestIdMiddleware)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Routers\napp.include_router(health.router)\napp.include_router(repositories.router)\napp.include_router(recommendations.router)\napp.include_router(dependencies.router)\napp.include_router(impact_analysis.router)\n\n\n@app.exception_handler(404)\nasync def not_found_handler(request: Request, exc):\n    body = error_response(request, code=\"NOT_FOUND\", message=\"Requested resource not found\")\n    return JSONResponse(status_code=404, content=body)\n\n\n@app.exception_handler(422)\nasync def validation_error_handler(request: Request, exc):\n    body = error_response(request, code=\"INVALID_REQUEST\", message=\"Validation error\", details={\"errors\": str(exc)})\n    return JSONResponse(status_code=400, content=body)\n\n\n@app.get(\"/\")\nasync def root(request: Request):\n    return {\"message\": \"CodeContext RAG API\", \"version\": settings.api_version}\n"
    },
    {
      "op": "write_file",
      "path": "tests/__init__.py",
      "mode": "overwrite",
      "content": ""
    },
    {
      "op": "write_file",
      "path": "tests/integration/test_health.py",
      "mode": "overwrite",
      "description": "Basic health endpoint test",
      "content": "from fastapi.testclient import TestClient\nfrom src.codecontext.main import app\n\nclient = TestClient(app)\n\n\ndef test_health():\n    r = client.get(\"/health\")\n    assert r.status_code == 200\n    data = r.json()\n    assert data[\"success\"] is True\n    assert data[\"data\"][\"status\"] in {\"healthy\", \"degraded\", \"unhealthy\"}\n    assert \"metadata\" in data\n"
    },
    {
      "op": "write_file",
      "path": "tests/integration/test_repositories.py",
      "mode": "overwrite",
      "description": "Repository lifecycle tests",
      "content": "from fastapi.testclient import TestClient\nfrom src.codecontext.main import app\n\nclient = TestClient(app)\n\n\ndef test_repository_register_list_get_delete():\n    # register\n    body = {\"name\": \"my-python-project\", \"source_type\": \"local\", \"source_path\": \"/tmp/project\"}\n    r = client.post(\"/repositories\", json=body)\n    assert r.status_code == 200\n    repo = r.json()[\"data\"]\n    repo_id = repo[\"id\"]\n\n    # list\n    r = client.get(\"/repositories\")\n    assert r.status_code == 200\n    repos = r.json()[\"data\"][\"repositories\"]\n    assert any(rp[\"id\"] == repo_id for rp in repos)\n\n    # get\n    r = client.get(f\"/repositories/{repo_id}\")\n    assert r.status_code == 200\n\n    # delete\n    r = client.delete(f\"/repositories/{repo_id}\")\n    assert r.status_code == 204\n"
    },
    {
      "op": "write_file",
      "path": "cli/codecontext_cli.py",
      "mode": "overwrite",
      "description": "Very simple CLI wrapper to hit health endpoint",
      "content": "import argparse\nimport requests\n\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"CodeContext RAG CLI\")\n    parser.add_argument(\"--base-url\", default=\"http://localhost:8000\", help=\"API base URL\")\n    args = parser.parse_args()\n\n    r = requests.get(f\"{args.base_url}/health\")\n    print(r.status_code, r.json())\n\n\nif __name__ == \"__main__\":\n    main()\n"
    }
  ]
}