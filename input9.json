{
  "version": "1.0",
  "backup": true,
"changes": [
    {
      "id": "llm-chat-db-js",
      "description": " Postgres-backed config store for llm-chat (tables + helpers, with pgcrypto).",
      "op": "write_file",
      "path": "modular-framework/modules/llm-chat/server/db.js",
      "mode": "create_if_missing",
      "content": "const { Pool } = require('pg');\n\nconst pool = new Pool({\n  host: process.env.PGHOST || 'postgres',\n  port: Number(process.env.PGPORT || 5432),\n  user: process.env.PGUSER || 'postgres',\n  password: process.env.PGPASSWORD || 'postgres',\n  database: process.env.PGDATABASE || 'llm_gateway',\n  max: 10\n});\n\nconst ENC_KEY = process.env.CONFIG_ENCRYPTION_KEY || null;\n\nasync function q(text, params) {\n  const client = await pool.connect();\n  try { return await client.query(text, params); }\n  finally { client.release(); }\n}\n\nasync function initDb() {\n  // Enable pgcrypto (once)\n  await q(`CREATE EXTENSION IF NOT EXISTS pgcrypto;`);\n\n  // Global config: single row (id=1)\n  await q(`\n    CREATE TABLE IF NOT EXISTS chat_global_config (\n      id SMALLINT PRIMARY KEY DEFAULT 1,\n      provider TEXT,\n      base_url TEXT,\n      api_key_enc BYTEA,\n      api_key_plain TEXT,\n      model TEXT,\n      temperature NUMERIC,\n      max_tokens INTEGER,\n      updated_at TIMESTAMP DEFAULT now()\n    );\n  `);\n\n  // Profiles: named\n  await q(`\n    CREATE TABLE IF NOT EXISTS chat_profiles (\n      id SERIAL PRIMARY KEY,\n      name TEXT NOT NULL UNIQUE,\n      provider TEXT,\n      base_url TEXT,\n      api_key_enc BYTEA,\n      api_key_plain TEXT,\n      model TEXT,\n      temperature NUMERIC,\n      max_tokens INTEGER,\n      system_prompt TEXT,\n      updated_at TIMESTAMP DEFAULT now()\n    );\n  `);\n}\n\n/* ===== Global config ===== */\nasync function readGlobalConfig() {\n  const sql = `\n    SELECT\n      provider, base_url, model, temperature, max_tokens,\n      CASE\n        WHEN $1::text IS NOT NULL AND api_key_enc IS NOT NULL THEN (pgp_sym_decrypt(api_key_enc, $1))::text\n        ELSE api_key_plain\n      END AS api_key\n    FROM chat_global_config WHERE id=1\n  `;\n  const { rows } = await q(sql, [ENC_KEY]);\n  if (!rows[0]) return null;\n  const r = rows[0];\n  return {\n    provider: r.provider || 'openai',\n    baseUrl: r.base_url || 'https://api.openai.com',\n    apiKey: r.api_key || '',\n    model: r.model || 'gpt-4o-mini',\n    temperature: r.temperature != null ? Number(r.temperature) : 0.7,\n    max_tokens: r.max_tokens != null ? Number(r.max_tokens) : undefined\n  };\n}\n\nasync function writeGlobalConfig(cfg) {\n  const {\n    provider, baseUrl, apiKey, model, temperature, max_tokens\n  } = cfg || {};\n  if (ENC_KEY) {\n    await q(`\n      INSERT INTO chat_global_config(id, provider, base_url, api_key_enc, api_key_plain, model, temperature, max_tokens, updated_at)\n      VALUES (1, $1, $2, pgp_sym_encrypt($3, $4), NULL, $5, $6, $7, now())\n      ON CONFLICT (id) DO UPDATE\n      SET provider=EXCLUDED.provider,\n          base_url=EXCLUDED.base_url,\n          api_key_enc=EXCLUDED.api_key_enc,\n          api_key_plain=NULL,\n          model=EXCLUDED.model,\n          temperature=EXCLUDED.temperature,\n          max_tokens=EXCLUDED.max_tokens,\n          updated_at=now()\n    `, [provider, baseUrl, apiKey || '', ENC_KEY, model, temperature, max_tokens]);\n  } else {\n    await q(`\n      INSERT INTO chat_global_config(id, provider, base_url, api_key_enc, api_key_plain, model, temperature, max_tokens, updated_at)\n      VALUES (1, $1, $2, NULL, $3, $4, $5, $6, now())\n      ON CONFLICT (id) DO UPDATE\n      SET provider=EXCLUDED.provider,\n          base_url=EXCLUDED.base_url,\n          api_key_enc=NULL,\n          api_key_plain=EXCLUDED.api_key_plain,\n          model=EXCLUDED.model,\n          temperature=EXCLUDED.temperature,\n          max_tokens=EXCLUDED.max_tokens,\n          updated_at=now()\n    `, [provider, baseUrl, apiKey || '', model, temperature, max_tokens]);\n  }\n  return await readGlobalConfig();\n}\n\n/* ===== Profiles ===== */\nfunction mapRowToProfile(r) {\n  return {\n    name: r.name,\n    provider: r.provider || undefined,\n    baseUrl: r.base_url || undefined,\n    apiKey: r.api_key || undefined,\n    model: r.model || undefined,\n    temperature: r.temperature != null ? Number(r.temperature) : undefined,\n    max_tokens: r.max_tokens != null ? Number(r.max_tokens) : undefined,\n    systemPrompt: r.system_prompt || ''\n  };\n}\nasync function listProfiles() {\n  const sql = `\n    SELECT\n      name, provider, base_url, model, temperature, max_tokens, system_prompt,\n      CASE\n        WHEN $1::text IS NOT NULL AND api_key_enc IS NOT NULL THEN (pgp_sym_decrypt(api_key_enc, $1))::text\n        ELSE api_key_plain\n      END AS api_key\n    FROM chat_profiles\n    ORDER BY name ASC\n  `;\n  const { rows } = await q(sql, [ENC_KEY]);\n  return rows.map(mapRowToProfile);\n}\n\nasync function replaceAllProfiles(arr = []) {\n  // transactional replace\n  const client = await pool.connect();\n  try {\n    await client.query('BEGIN');\n    await client.query('DELETE FROM chat_profiles');\n    for (const p of arr) {\n      const {\n        name, provider, baseUrl, apiKey, model, temperature, max_tokens, systemPrompt\n      } = p || {};\n      if (!name) continue;\n      if (ENC_KEY) {\n        await client.query(`\n          INSERT INTO chat_profiles(name, provider, base_url, api_key_enc, api_key_plain, model, temperature, max_tokens, system_prompt, updated_at)\n          VALUES ($1,$2,$3, pgp_sym_encrypt($4,$5), NULL, $6,$7,$8,$9, now())\n        `, [name, provider || null, baseUrl || null, apiKey || '', ENC_KEY, model || null, temperature || null, max_tokens || null, systemPrompt || '']);\n      } else {\n        await client.query(`\n          INSERT INTO chat_profiles(name, provider, base_url, api_key_enc, api_key_plain, model, temperature, max_tokens, system_prompt, updated_at)\n          VALUES ($1,$2,$3, NULL, $4, $5,$6,$7,$8, now())\n        `, [name, provider || null, baseUrl || null, apiKey || '', model || null, temperature || null, max_tokens || null, systemPrompt || '']);\n      }\n    }\n    await client.query('COMMIT');\n  } catch (e) {\n    try { await client.query('ROLLBACK'); } catch {}\n    throw e;\n  } finally {\n    client.release();\n  }\n  return await listProfiles();\n}\n\nmodule.exports = {\n  initDb,\n  readGlobalConfig, writeGlobalConfig,\n  listProfiles, replaceAllProfiles\n};\n"
    },
    {
      "id": "llm-chat-config-store-route",
      "description": "Add config store routes for llm-chat to read/write global and profiles from DB.",
      "op": "write_file",
      "path": "modular-framework/modules/llm-chat/server/routes/configStore.js",
      "mode": "create_if_missing",
      "content": "const express = require('express');\nconst router = express.Router();\nconst {\n  readGlobalConfig, writeGlobalConfig,\n  listProfiles, replaceAllProfiles\n} = require('../db');\nconst { logInfo } = require('../logger');\n\nfunction optionalAuth(req, res, next) {\n  const token = process.env.INTERNAL_API_TOKEN;\n  if (!token) return next(); // dev-friendly\n  const hdr = req.headers['authorization'] || '';\n  if (hdr === `Bearer ${token}`) return next();\n  return res.status(401).json({ error: 'unauthorized' });\n}\n\nrouter.get('/config-store/global', optionalAuth, async (_req, res) => {\n  try {\n    const cfg = await readGlobalConfig();\n    res.json({ ok: true, config: cfg || null });\n  } catch (e) {\n    res.status(500).json({ ok: false, error: e.message || 'read failed' });\n  }\n});\nrouter.put('/config-store/global', optionalAuth, async (req, res) => {\n  const body = req.body || {};\n  try {\n    const saved = await writeGlobalConfig({\n      provider: body.provider || null,\n      baseUrl: body.baseUrl || null,\n      apiKey: body.apiKey || '',\n      model: body.model || null,\n      temperature: body.temperature != null ? Number(body.temperature) : null,\n      max_tokens: body.max_tokens != null ? Number(body.max_tokens) : null\n    });\n    logInfo('chat:config:global:updated', { ip: req.ip });\n    res.json({ ok: true, config: saved });\n  } catch (e) {\n    res.status(400).json({ ok: false, error: e.message || 'save failed' });\n  }\n});\n\nrouter.get('/config-store/profiles', optionalAuth, async (_req, res) => {\n  try {\n    const items = await listProfiles();\n    res.json({ ok: true, items });\n  } catch (e) {\n    res.status(500).json({ ok: false, error: e.message || 'read failed' });\n  }\n});\nrouter.put('/config-store/profiles', optionalAuth, async (req, res) => {\n  const items = Array.isArray(req.body?.items) ? req.body.items : [];\n  try {\n    const saved = await replaceAllProfiles(items);\n    logInfo('chat:config:profiles:replaced', { count: saved.length });\n    res.json({ ok: true, items: saved });\n  } catch (e) {\n    res.status(400).json({ ok: false, error: e.message || 'replace failed' });\n  }\n});\n\nmodule.exports = { router };\n"
    },
    {
      "id": "llm-chat-app-js-overwrite",
      "description": "Mount config store routes and initialize DB in llm-chat server app.",
      "op": "write_file",
      "path": "modular-framework/modules/llm-chat/server/app.js",
      "mode": "overwrite",
      "content": "const express = require('express');\nconst cors = require('cors');\nconst path = require('path');\nconst bodyParser = require('body-parser');\n\nconst { router: logsRouter } = require('./routes/logs');\nconst { router: infoRouter } = require('./routes/info');\nconst { router: healthRouter } = require('./routes/health');\nconst { router: chatRouter } = require('./routes/chat');\nconst { router: workflowsRouter } = require('./routes/workflows');\nconst { router: agentRouter } = require('./routes/agent');\nconst { router: loggingRouter } = require('./routes/logging');\n\nconst { stamp, logInfo, logError } = require('./logger');\nconst { initDb } = require('./db');\nconst { router: configStoreRouter } = require('./routes/configStore');\n\nconst app = express();\n\nconst BASE_PATH = (process.env.BASE_PATH || '').replace(/\\/$/, ''); // e.g. \"/modules/llm-chat\" or \"\"\n\n// middleware\napp.use(cors({ origin: true, credentials: true }));\napp.use(bodyParser.json({ limit: '2mb' }));\napp.use(stamp);\n\n// lightweight HTTP access logging (to Splunk)\napp.use((req, res, next) => {\n  const start = process.hrtime.bigint();\n  res.on('finish', () => {\n    const durMs = Number(process.hrtime.bigint() - start) / 1e6;\n    logInfo('http_access', {\n      rid: req.id,\n      method: req.method,\n      path: req.originalUrl || req.url,\n      status: res.statusCode,\n      duration_ms: Math.round(durMs),\n      ip: req.headers['x-forwarded-for'] || req.socket?.remoteAddress || 'unknown',\n      ua: req.headers['user-agent'] || ''\n    });\n  });\n  next();\n});\n\n// static UI\nconst pub = path.join(__dirname, '..', 'public');\n\n// Serve both at root and at BASE_PATH to support either proxy style\napp.use(express.static(pub));\nif (BASE_PATH) app.use(BASE_PATH, express.static(pub));\n\napp.get('/', (_req, res) => res.sendFile(path.join(pub, 'index.html')));\nif (BASE_PATH) app.get(`${BASE_PATH}/`, (_req, res) => res.sendFile(path.join(pub, 'index.html')));\n\napp.get('/config', (_req, res) => res.sendFile(path.join(pub, 'config.html')));\nif (BASE_PATH) app.get(`${BASE_PATH}/config`, (_req, res) => res.sendFile(path.join(pub, 'config.html')));\n\n// admin logging API (for logging orchestrator)\napp.use('/admin-api', loggingRouter);\nif (BASE_PATH) app.use(`${BASE_PATH}/admin-api`, loggingRouter);\n\n// health/info/logs\napp.use('/', healthRouter);            // /health (root for Docker healthcheck)\napp.use('/api', infoRouter);           // /api/info\napp.use('/api', logsRouter);           // /api/logs, /api/logs/clear\nif (BASE_PATH) {\n  app.use(`${BASE_PATH}/api`, infoRouter);  // /modules/llm-chat/api/info\n  app.use(`${BASE_PATH}/api`, logsRouter);  // /modules/llm-chat/api/logs\n}\n\n// workflows + agent routes\napp.use('/api', workflowsRouter);\napp.use('/api', agentRouter);\nif (BASE_PATH) {\n  app.use(`${BASE_PATH}/api`, workflowsRouter);\n  app.use(`${BASE_PATH}/api`, agentRouter);\n}\n\n// chat routes (root and prefixed)\napp.use('/api', chatRouter); // /api/chat\nif (BASE_PATH) app.use(`${BASE_PATH}/api`, chatRouter); // /modules/llm-chat/api/chat\n\n// NEW: config-store (DB-backed settings)\napp.use('/api', configStoreRouter);\nif (BASE_PATH) app.use(`${BASE_PATH}/api`, configStoreRouter);\n\n// central error handler (ensures errors are logged and returned as JSON)\napp.use((err, _req, res, _next) => {\n  try {\n    logError('unhandled_error', { message: err?.message || String(err), stack: err?.stack });\n  } catch {}\n  res.status(500).json({ error: 'Internal Server Error' });\n});\n\n// init DB once\ninitDb().catch(err => {\n  console.error('llm-chat DB init failed', err);\n  process.exit(1);\n});\n\nmodule.exports = app;\n"
    },
    {
      "id": "llm-chat-package-json",
      "description": "Add pg dependency to llm-chat.",
      "op": "write_file",
      "path": "modular-framework/modules/llm-chat/package.json",
      "mode": "overwrite",
      "content": "{\n  \"name\": \"llm-chat-module\",\n  \"version\": \"1.0.0\",\n  \"description\": \"LLM Chat module for modular web framework\",\n  \"main\": \"server/index.js\",\n  \"scripts\": {\n    \"start\": \"node server/index.js\",\n    \"dev\": \"nodemon server/index.js\"\n  },\n  \"dependencies\": {\n    \"axios\": \"^1.7.2\",\n    \"body-parser\": \"^1.20.2\",\n    \"cors\": \"^2.8.5\",\n    \"express\": \"^4.19.2\",\n    \"pg\": \"^8.12.0\"\n  },\n  \"devDependencies\": {\n    \"nodemon\": \"^3.1.0\"\n  }\n}\n"
    },
    {
      "id": "llm-chat-storage-js",
      "description": "Make llm-chat storage use server-backed config store (fallback to localStorage).",
      "op": "write_file",
      "path": "modular-framework/modules/llm-chat/public/js/storage.js",
      "mode": "overwrite",
      "content": "export const LS = {\n  GLOBAL: 'llmChatConfig',\n  PROFILES: 'llmChatProfiles',\n  ACTIVE: 'llmChatActiveProfile',\n};\n\n// Optional bearer token for internal APIs (set via localStorage to enforce)\nfunction internalAuthHeaders() {\n  const tok = localStorage.getItem('internalApiToken') || '';\n  return tok ? { Authorization: `Bearer ${tok}` } : {};\n}\n\n// Try server first, fallback to localStorage\nasync function fetchServerGlobal() {\n  try {\n    const res = await fetch('./api/config-store/global', { headers: { ...internalAuthHeaders() } });\n    if (!res.ok) return null;\n    const data = await res.json();\n    return data?.config || null;\n  } catch { return null; }\n}\nasync function saveServerGlobal(cfg) {\n  try {\n    const res = await fetch('./api/config-store/global', {\n      method: 'PUT',\n      headers: { 'Content-Type': 'application/json', ...internalAuthHeaders() },\n      body: JSON.stringify(cfg)\n    });\n    return res.ok;\n  } catch { return false; }\n}\nasync function fetchServerProfiles() {\n  try {\n    const res = await fetch('./api/config-store/profiles', { headers: { ...internalAuthHeaders() } });\n    if (!res.ok) return null;\n    const data = await res.json();\n    return Array.isArray(data?.items) ? data.items : null;\n  } catch { return null; }\n}\nasync function saveServerProfiles(arr) {\n  try {\n    const res = await fetch('./api/config-store/profiles', {\n      method: 'PUT',\n      headers: { 'Content-Type': 'application/json', ...internalAuthHeaders() },\n      body: JSON.stringify({ items: arr || [] })\n    });\n    return res.ok;\n  } catch { return false; }\n}\n\nexport const defaultProfiles = [\n  { name:'Frontend Engineer', provider:'openai', baseUrl:'https://api.openai.com', model:'gpt-4o-mini',\n    systemPrompt:`You are a senior Frontend Engineer. Give precise, practical advice on HTML, CSS, JS, accessibility, and performance. Prefer code snippets and explain trade-offs briefly.` },\n  { name:'React Specialist', provider:'openai', baseUrl:'https://api.openai.com', model:'gpt-4o-mini',\n    systemPrompt:`You are a React expert. Use modern React (hooks, functional components), TypeScript-friendly patterns, and explain render/performance implications.` },\n  { name:'Security Reviewer', provider:'openai-compatible', baseUrl:'https://api.together.xyz', model:'meta-llama/Meta-Llama-3-70B-Instruct-Turbo',\n    systemPrompt:`Act as an application security reviewer. Identify vulnerabilities, threat models, and provide actionable remediations with clear risk levels.` },\n  { name:'DevOps/SRE', provider:'ollama', baseUrl:'http://ollama:11434', model:'llama3',\n    systemPrompt:`You are a pragmatic SRE. Provide concise, command-ready steps, incident runbooks, and rollback strategies.` },\n  { name:'Data Scientist', provider:'openai-compatible', baseUrl:'https://api.openrouter.ai', model:'mistralai/mixtral-8x7b-instruct',\n    systemPrompt:`You are a data scientist. Explain assumptions, feature engineering, eval metrics, and provide Python snippets when helpful.` },\n  { name:'Socratic Tutor', provider:'openai', baseUrl:'https://api.openai.com', model:'gpt-4o-mini',\n    systemPrompt:`Teach by asking guiding questions. Don’t give the answer outright; scaffold thinking and provide hints in steps.` },\n  { name:'Unit Test Generator', provider:'openai', baseUrl:'https://api.openai.com', model:'gpt-4o-mini',\n    systemPrompt:`Generate high-coverage unit tests with table-driven cases, edge conditions, and clear arrange/act/assert structure.` },\n  { name:'Product Manager', provider:'openai', baseUrl:'https://api.openai.com', model:'gpt-4o-mini',\n    systemPrompt:`Focus on user value, scope, acceptance criteria, and trade-offs. Produce crisp PRDs and success metrics.` }\n];\n\nlet cachedGlobal = null;\nlet cachedProfiles = null;\n\n// Global config: async load from server on first get\nexport function getGlobal() {\n  if (cachedGlobal) return cachedGlobal;\n  // Start from localStorage fallback synchronously\n  const raw = localStorage.getItem(LS.GLOBAL);\n  const cfg = raw ? JSON.parse(raw) : {};\n  cachedGlobal = {\n    provider: cfg.provider || 'openai',\n    baseUrl:  cfg.baseUrl  || 'https://api.openai.com',\n    apiKey:   cfg.apiKey   || '',\n    model:    cfg.model    || 'gpt-4o-mini',\n    temperature: Number(cfg.temperature ?? 0.7),\n    max_tokens: cfg.max_tokens ? Number(cfg.max_tokens) : undefined\n  };\n  // Async refresh from server\n  fetchServerGlobal().then((serverCfg) => {\n    if (serverCfg) {\n      cachedGlobal = serverCfg;\n      localStorage.setItem(LS.GLOBAL, JSON.stringify(serverCfg));\n    }\n  }).catch(()=>{});\n  return cachedGlobal;\n}\n\nexport function setGlobal(cfg) {\n  cachedGlobal = { ...cfg };\n  localStorage.setItem(LS.GLOBAL, JSON.stringify(cachedGlobal));\n  // fire-and-forget save to server\n  saveServerGlobal(cachedGlobal).catch(()=>{});\n}\n\nexport function getProfiles() {\n  if (cachedProfiles) return cachedProfiles;\n  // local fallback\n  const raw = localStorage.getItem(LS.PROFILES);\n  const arr = raw ? JSON.parse(raw) : defaultProfiles;\n  cachedProfiles = arr;\n  if (!raw) localStorage.setItem(LS.PROFILES, JSON.stringify(arr));\n  // async refresh\n  fetchServerProfiles().then((serverArr) => {\n    if (serverArr && serverArr.length) {\n      cachedProfiles = serverArr;\n      localStorage.setItem(LS.PROFILES, JSON.stringify(serverArr));\n    }\n  }).catch(()=>{});\n  return cachedProfiles;\n}\n\nexport function setProfiles(arr) {\n  cachedProfiles = Array.isArray(arr) ? arr : [];\n  localStorage.setItem(LS.PROFILES, JSON.stringify(cachedProfiles));\n  saveServerProfiles(cachedProfiles).catch(()=>{});\n}\n\nexport function getActiveName() { return localStorage.getItem(LS.ACTIVE) || getProfiles()[0]?.name || ''; }\nexport function setActiveName(name) { localStorage.setItem(LS.ACTIVE, name || ''); }\n"
    },
    {
      "id": "llm-ide-backend-db-js",
      "description": "Add Postgres + pgcrypto-backed SSH presets for llm-ide backend.",
      "op": "write_file",
      "path": "modular-framework/modules/llm-ide/backend/db.js",
      "mode": "create_if_missing",
      "content": "import { Pool } from 'pg';\n\nconst pool = new Pool({\n  host: process.env.PGHOST || 'postgres',\n  port: Number(process.env.PGPORT || 5432),\n  user: process.env.PGUSER || 'postgres',\n  password: process.env.PGPASSWORD || 'postgres',\n  database: process.env.PGDATABASE || 'llm_gateway',\n  max: 10\n});\n\nconst ENC_KEY = process.env.CONFIG_ENCRYPTION_KEY || null;\n\nasync function q(text, params) {\n  const client = await pool.connect();\n  try { return await client.query(text, params); }\n  finally { client.release(); }\n}\n\nexport async function initDb() {\n  await q(`CREATE EXTENSION IF NOT EXISTS pgcrypto;`);\n  await q(`\n    CREATE TABLE IF NOT EXISTS ide_ssh_presets (\n      id SERIAL PRIMARY KEY,\n      name TEXT NOT NULL UNIQUE,\n      host TEXT NOT NULL,\n      port INTEGER DEFAULT 22,\n      username TEXT NOT NULL,\n      auth_method TEXT NOT NULL CHECK (auth_method IN ('password','key')),\n      password_enc BYTEA,\n      password_plain TEXT,\n      private_key_enc BYTEA,\n      private_key_plain TEXT,\n      passphrase_enc BYTEA,\n      passphrase_plain TEXT,\n      created_at TIMESTAMP DEFAULT now(),\n      updated_at TIMESTAMP DEFAULT now()\n    );\n  `);\n}\n\nfunction encOrPlain(columnEnc, columnPlain, val) {\n  if (!val) return { enc: null, plain: null };\n  if (ENC_KEY) return { enc: { col: columnEnc, val }, plain: { col: columnPlain, val: null } };\n  return { enc: { col: columnEnc, val: null }, plain: { col: columnPlain, val } };\n}\n\nexport async function listPresets() {\n  const sql = `\n    SELECT\n      id, name, host, port, username, auth_method,\n      CASE WHEN $1::text IS NOT NULL AND password_enc IS NOT NULL THEN (pgp_sym_decrypt(password_enc,$1))::text ELSE password_plain END AS password,\n      CASE WHEN $1::text IS NOT NULL AND private_key_enc IS NOT NULL THEN (pgp_sym_decrypt(private_key_enc,$1))::text ELSE private_key_plain END AS private_key,\n      CASE WHEN $1::text IS NOT NULL AND passphrase_enc IS NOT NULL THEN (pgp_sym_decrypt(passphrase_enc,$1))::text ELSE passphrase_plain END AS passphrase\n    FROM ide_ssh_presets\n    ORDER BY name ASC\n  `;\n  const { rows } = await q(sql, [ENC_KEY]);\n  return rows;\n}\n\nexport async function getPreset(id) {\n  const sql = `\n    SELECT\n      id, name, host, port, username, auth_method,\n      CASE WHEN $1::text IS NOT NULL AND password_enc IS NOT NULL THEN (pgp_sym_decrypt(password_enc,$1))::text ELSE password_plain END AS password,\n      CASE WHEN $1::text IS NOT NULL AND private_key_enc IS NOT NULL THEN (pgp_sym_decrypt(private_key_enc,$1))::text ELSE private_key_plain END AS private_key,\n      CASE WHEN $1::text IS NOT NULL AND passphrase_enc IS NOT NULL THEN (pgp_sym_decrypt(passphrase_enc,$1))::text ELSE passphrase_plain END AS passphrase\n    FROM ide_ssh_presets WHERE id=$2\n  `;\n  const { rows } = await q(sql, [ENC_KEY, Number(id)]);\n  return rows[0] || null;\n}\n\nexport async function createPreset(p) {\n  const pw = encOrPlain('password_enc','password_plain', p.password || null);\n  const key = encOrPlain('private_key_enc','private_key_plain', p.private_key || null);\n  const pp = encOrPlain('passphrase_enc','passphrase_plain', p.passphrase || null);\n\n  // Build dynamic SQL depending on encryption mode\n  const fields = ['name','host','port','username','auth_method',\n    pw.enc.col, pw.plain.col, key.enc.col, key.plain.col, pp.enc.col, pp.plain.col, 'updated_at'\n  ];\n  const values = [\n    p.name, p.host, p.port || 22, p.username, p.auth_method,\n    pw.enc.val ? { enc: true, val: pw.enc.val } : null,\n    pw.plain.val,\n    key.enc.val ? { enc: true, val: key.enc.val } : null,\n    key.plain.val,\n    pp.enc.val ? { enc: true, val: pp.enc.val } : null,\n    pp.plain.val,\n    new Date()\n  ];\n\n  // Translate enc markers into pgp_sym_encrypt calls\n  const placeholders = values.map((v, i) => {\n    if (v && v.enc) return `pgp_sym_encrypt($${i+1}, $${values.length+1})`;\n    return `$${i+1}`;\n  });\n\n  const sql = `\n    INSERT INTO ide_ssh_presets (${fields.join(',')})\n    VALUES (${placeholders.join(',')})\n    RETURNING *\n  `;\n  const params = values.map(v => (v && v.enc) ? v.val : v);\n  params.push(ENC_KEY); // last param for encryption calls\n  const { rows } = await q(sql, params);\n  return rows[0];\n}\n\nexport async function updatePreset(id, p) {\n  const pw = encOrPlain('password_enc','password_plain', p.password || null);\n  const key = encOrPlain('private_key_enc','private_key_plain', p.private_key || null);\n  const pp = encOrPlain('passphrase_enc','passphrase_plain', p.passphrase || null);\n\n  const sets = [\n    'name=$1','host=$2','port=$3','username=$4','auth_method=$5'\n  ];\n  const params = [p.name, p.host, p.port || 22, p.username, p.auth_method];\n\n  function pushEncOrPlain(encPlain, nextIndexStart) {\n    if (ENC_KEY) {\n      sets.push(`${encPlain.enc.col}=pgp_sym_encrypt($${nextIndexStart}, $${nextIndexStart+1})`);\n      sets.push(`${encPlain.plain.col}=NULL`);\n      params.push(encPlain.enc.val || '');\n      params.push(ENC_KEY);\n      return nextIndexStart + 2;\n    } else {\n      sets.push(`${encPlain.enc.col}=NULL`);\n      sets.push(`${encPlain.plain.col}=$${nextIndexStart}`);\n      params.push(encPlain.plain.val || null);\n      return nextIndexStart + 1;\n    }\n  }\n\n  let idx = 6;\n  idx = pushEncOrPlain(pw, idx);\n  idx = pushEncOrPlain(key, idx);\n  idx = pushEncOrPlain(pp, idx);\n  sets.push(`updated_at=now()`);\n\n  const sql = `UPDATE ide_ssh_presets SET ${sets.join(',')} WHERE id=$${idx} RETURNING *`;\n  params.push(Number(id));\n  const { rows } = await q(sql, params);\n  return rows[0];\n}\n\nexport async function deletePreset(id) {\n  await q(`DELETE FROM ide_ssh_presets WHERE id=$1`, [Number(id)]);\n  return true;\n}\n"
    },
    {
      "id": "llm-ide-backend-presets-router",
      "description": "Add presets CRUD router to llm-ide backend.",
      "op": "write_file",
      "path": "modular-framework/modules/llm-ide/backend/presets.js",
      "mode": "create_if_missing",
      "content": "import express from 'express';\nimport { initDb, listPresets, getPreset, createPreset, updatePreset, deletePreset } from './db.js';\n\nconst router = express.Router();\n\n// Optional simple bearer auth for write ops (set INTERNAL_API_TOKEN in env)\nfunction requireWriteAuth(req, res, next) {\n  const token = process.env.INTERNAL_API_TOKEN;\n  if (!token) return next();\n  const hdr = req.headers['authorization'] || '';\n  if (hdr === `Bearer ${token}`) return next();\n  return res.status(401).json({ error: 'unauthorized' });\n}\n\nrouter.get('/presets', async (_req, res) => {\n  try { res.json({ ok: true, items: await listPresets() }); }\n  catch (e) { res.status(500).json({ ok: false, error: e.message || 'list failed' }); }\n});\n\nrouter.get('/presets/:id', async (req, res) => {\n  try {\n    const item = await getPreset(req.params.id);\n    if (!item) return res.status(404).json({ ok: false, error: 'not found' });\n    res.json({ ok: true, item });\n  } catch (e) {\n    res.status(500).json({ ok: false, error: e.message || 'get failed' });\n  }\n});\n\nrouter.post('/presets', requireWriteAuth, async (req, res) => {\n  try { res.json({ ok: true, item: await createPreset(req.body || {}) }); }\n  catch (e) { res.status(400).json({ ok: false, error: e.message || 'create failed' }); }\n});\n\nrouter.put('/presets/:id', requireWriteAuth, async (req, res) => {\n  try { res.json({ ok: true, item: await updatePreset(req.params.id, req.body || {}) }); }\n  catch (e) { res.status(400).json({ ok: false, error: e.message || 'update failed' }); }\n});\n\nrouter.delete('/presets/:id', requireWriteAuth, async (req, res) => {\n  try { await deletePreset(req.params.id); res.json({ ok: true }); }\n  catch (e) { res.status(400).json({ ok: false, error: e.message || 'delete failed' }); }\n});\n\nexport { router };\n"
    },
    {
      "id": "llm-ide-backend-server-js-overwrite",
      "description": "Mount presets API and allow /ssh/connect by presetId in llm-ide backend; init DB.",
      "op": "write_file",
      "path": "modular-framework/modules/llm-ide/backend/server.js",
      "mode": "overwrite",
      "content": "import express from 'express';\nimport http from 'http';\nimport cors from 'cors';\nimport { WebSocketServer } from 'ws';\nimport { createSession, attachWebSocket, disconnect, listRemote, readRemote, writeRemote, mkdirRemote } from './sshManager.js';\nimport { initDb, getPreset } from './db.js';\nimport { router as presetsRouter } from './presets.js';\n\nconst PORT = process.env.PORT || 3021;\nconst app = express();\napp.use(cors({ origin: true, credentials: true }));\napp.use(express.json({ limit: '256kb' }));\n\n// Presets API\napp.use('/', presetsRouter);\n\n// --- HTTP API ---\napp.post('/ssh/connect', async (req, res) => {\n  try {\n    const { presetId } = req.body || {};\n    let cfg = req.body || {};\n    if (presetId) {\n      const p = await getPreset(presetId);\n      if (!p) return res.status(404).json({ ok: false, error: 'Preset not found' });\n      cfg = {\n        host: p.host,\n        port: p.port || 22,\n        username: p.username,\n        authMethod: p.auth_method,\n        password: p.password || undefined,\n        privateKey: p.private_key || undefined,\n        passphrase: p.passphrase || undefined\n      };\n    }\n    const { host, port = 22, username, authMethod } = cfg;\n    if (!host || !username || !authMethod) {\n      return res.status(400).json({ ok: false, error: 'Missing required fields' });\n    }\n    console.log('[api] /ssh/connect', { host, port, username, authMethod, preset: !!presetId });\n    const { sessionId } = await createSession(cfg);\n    return res.json({ ok: true, sessionId });\n  } catch (err) {\n    console.error('[api] connect failed', err?.message || err);\n    return res.status(500).json({ ok: false, error: err?.message || 'Connect failed' });\n  }\n});\n\napp.get('/ssh/list', async (req, res) => {\n  try {\n    const sessionId = req.query.sessionId;\n    const path = req.query.path;\n    const depth = Math.max(0, Math.min(5, parseInt(req.query.depth || '2', 10)));\n    if (!sessionId || !path) return res.status(400).json({ ok: false, error: 'Missing sessionId or path' });\n    const tree = await listRemote(sessionId, path, depth);\n    return res.json({ ok: true, tree });\n  } catch (err) {\n    console.error('[api] list failed', err?.message || err);\n    return res.status(500).json({ ok: false, error: err?.message || 'List failed' });\n  }\n});\n\napp.get('/ssh/read', async (req, res) => {\n  try {\n    const sessionId = req.query.sessionId;\n    const path = req.query.path;\n    if (!sessionId || !path) return res.status(400).json({ ok: false, error: 'Missing sessionId or path' });\n    const content = await readRemote(sessionId, path);\n    return res.json({ ok: true, content });\n  } catch (err) {\n    console.error('[api] read failed', err?.message || err);\n    return res.status(500).json({ ok: false, error: err?.message || 'Read failed' });\n  }\n});\n\n\napp.post('/ssh/write', async (req, res) => {\n  try {\n    const { sessionId, path, content } = req.body || {};\n    if (!sessionId || !path) return res.status(400).json({ ok: false, error: 'Missing sessionId or path' });\n    await writeRemote(sessionId, path, content ?? '');\n    return res.json({ ok: true });\n  } catch (err) {\n    console.error('[api] write failed', err?.message || err);\n    return res.status(500).json({ ok: false, error: err?.message || 'Write failed' });\n  }\n});\n\napp.post('/ssh/mkdir', async (req, res) => {\n  try {\n    const { sessionId, path, recursive = true } = req.body || {};\n    if (!sessionId || !path) return res.status(400).json({ ok: false, error: 'Missing sessionId or path' });\n    await mkdirRemote(sessionId, path, { recursive: !!recursive });\n    return res.json({ ok: true });\n  } catch (err) {\n    console.error('[api] mkdir failed', err?.message || err);\n    return res.status(500).json({ ok: false, error: err?.message || 'Mkdir failed' });\n  }\n});\n\napp.post('/ssh/disconnect', (req, res) => {\n  const { sessionId } = req.body || {};\n  if (!sessionId) return res.status(400).json({ ok: false, error: 'Missing sessionId' });\n  disconnect(sessionId);\n  return res.json({ ok: true });\n});\n\n// --- HTTP -> WS server ---\nconst server = http.createServer(app);\nconst wss = new WebSocketServer({ noServer: true });\n\nserver.on('upgrade', (request, socket, head) => {\n  const url = new URL(request.url, `http://${request.headers.host}`);\n  if (url.pathname !== '/ssh') { socket.destroy(); return; }\n  const sessionId = url.searchParams.get('sessionId');\n  if (!sessionId) { socket.destroy(); return; }\n  wss.handleUpgrade(request, socket, head, (ws) => {\n    attachWebSocket(sessionId, ws);\n  });\n});\n\ninitDb().then(() => {\n  server.listen(PORT, () => console.log(`[SSH-Bridge] Listening on ${PORT}`));\n}).catch((e) => {\n  console.error('ide-backend DB init failed', e);\n  process.exit(1);\n});\n"
    },
    {
      "id": "llm-ide-backend-package-json",
      "description": "Add pg dependency to llm-ide backend.",
      "op": "write_file",
      "path": "modular-framework/modules/llm-ide/backend/package.json",
      "mode": "overwrite",
      "content": "{\n  \"name\": \"ide-ssh-bridge\",\n  \"version\": \"1.0.0\",\n  \"private\": true,\n  \"type\": \"module\",\n  \"scripts\": {\n    \"start\": \"node server.js\",\n    \"dev\": \"NODE_ENV=development node server.js\"\n  },\n  \"dependencies\": {\n    \"cors\": \"^2.8.5\",\n    \"express\": \"^4.19.2\",\n    \"pg\": \"^8.12.0\",\n    \"ssh2\": \"^1.15.0\",\n    \"uuid\": \"^9.0.1\",\n    \"ws\": \"^8.18.0\"\n  }\n}\n"
    },
    {
      "id": "compose-overwrite",
      "description": "Update docker-compose to pass Postgres and encryption env to llm-chat and llm-ide-backend; add depends_on.",
      "op": "write_file",
      "path": "modular-framework/modules/docker-compose.yml",
      "mode": "overwrite",
      "content": "version: '3.8'\n\nservices:\n  # Main Framework Container with Nginx# Edge Nginx (reverse proxy & TLS terminator)\n  edge-nginx:\n    build: ./edge-nginx\n    container_name: edge-nginx\n    ports:\n      - \"8080:80\"\n      - \"8443:443\"\n    volumes:\n      - ./edge-nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n\n    depends_on:\n      - framework-web\n      - rag-api-module\n      - github-hub-module\n      - llm-chat\n      - llm-workflows-module\n      - llm-gateway\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  # Framework static website (served behind edge-nginx)\n  framework-web:\n    build: ./framework\n    container_name: framework-web\n    expose:\n      - \"80\"\n    volumes:\n      - ./framework/html:/usr/share/nginx/html\n      - ./framework/nginx.conf:/etc/nginx/nginx.conf\n    depends_on:\n      - rag-api-module\n      - github-hub-module\n      - llm-chat\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  # SSH Terminal Module Container\n# SSH Terminal Module Container\n  #ssh-terminal:\n  #  build: ./ssh-terminal\n  #  container_name: ssh-terminal-module\n  #  ports:\n  #    - \"3001:3001\"\n  #  environment:\n  #    - NODE_ENV=production\n  #    - PORT=3001\n  #  networks:\n  #    - app-network\n  #  restart: unless-stopped\n\n  llm-workflows-module:\n    build: ./llm-workflows\n    container_name: llm-workflows-module\n    environment:\n      - SPLUNK_HEC_URL=$SPLUNK_HEC_URL\n      - SPLUNK_HEC_TOKEN=$SPLUNK_HEC_TOKEN\n      - NODE_TLS_REJECT_UNAUTHORIZED=${NODE_TLS_REJECT_UNAUTHORIZED}\n      - NODE_ENV=production\n      - PORT=3005\n      # Point to llm-gateway compat endpoint designed for workflows SSE\n      - LLM_GATEWAY_CHAT_URL=http://llm-gateway:3010/api/compat/llm-workflows\n      # Base for admin/models APIs\n      - LLM_GATEWAY_API_BASE=http://llm-gateway:3010/api\n      # Optional: serve UI under a path instead of \"/\"\n      - BASE_PATH=/llm-workflows\n      # Optional & DANGEROUS: only set to true if you want to allow host execution\n      # - ALLOW_DANGEROUS=true\n      # Optional: choose where workflows.json is stored (default is /app/data)\n      # - DATA_DIR=/app/data\n    expose:\n      - \"3005\"\n    volumes:\n      # persist workflows.json\n      - ./llm-workflows/data:/app/data\n    depends_on:\n      - llm-gateway\n      - splunk\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  github-hub-module:\n    build:\n      context: ./github-hub\n    container_name: github-hub-module\n    environment:\n      - PORT=3005\n      - GITHUB_TOKEN=${GITHUB_TOKEN}\n      - GH_TOKEN_KEY=${GH_TOKEN_KEY}\n      - DATA_DIR=/data\n    volumes:\n      - ./github-hub/data:/data\n    expose:\n      - \"3005\"\n    networks:\n      - app-network\n\n  llm-chat:\n    build: ./llm-chat\n    container_name: llm-chat-module\n    ports:\n      - \"3004:3004\"\n    env_file: ./.env\n    environment:\n      - NODE_ENV=production\n      - NODE_TLS_REJECT_UNAUTHORIZED=${NODE_TLS_REJECT_UNAUTHORIZED}\n      - PORT=3004\n      - SPLUNK_HEC_URL=${SPLUNK_HEC_URL}      \n      - LOG_TO_CONSOLE=false\n      - SPLUNK_HEC_TOKEN=${SPLUNK_HEC_TOKEN}\n      - SPLUNK_SOURCE=llm-chat\n      # Postgres (reuse gateway DB)\n      - PGHOST=postgres\n      - PGPORT=5432\n      - PGUSER=postgres\n      - PGPASSWORD=postgres\n      - PGDATABASE=llm_gateway\n      # Encryption key for secrets-at-rest\n      - CONFIG_ENCRYPTION_KEY=${CONFIG_ENCRYPTION_KEY}\n    depends_on:\n      - splunk\n      - postgres\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  #browser-module:\n  #  build: ./browser\n  #  container_name: browser-module\n  #  environment:\n  #    - PORT=3008\n  #    - PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true\n  #    - PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser\n  #  expose:\n  #    - \"3008\"\n  #  networks:\n  #    - app-network\n  #  restart: unless-stopped\n\n  qdrant:\n    image: qdrant/qdrant:latest\n    ports:\n      - \"6333:6333\"\n    volumes:\n      - ./RAG/qdrant_storage:/qdrant/storage\n    networks:\n        - app-network\n    environment:\n      - QDRANT__LOG_LEVEL=INFO\n\n  redis:\n    image: redis:7-alpine\n    ports:\n      - \"6379:6379\"\n    networks:\n        - app-network\n    volumes:\n      - ./RAG/redis_data:/data\n\n  rag-api-module:\n    build: ./RAG\n    container_name: rag-api-module\n    env_file: .env\n    ports:\n      - \"8000:8000\"\n    environment:\n      - QDRANT_URL=http://qdrant:6333\n      - REDIS_HOST=redis\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n    depends_on:\n      - qdrant\n      - redis\n    networks:\n        - app-network\n    volumes:\n      - ./RAG/logs:/app/logs\n\n  postgres:\n    image: postgres:14-alpine\n    container_name: postgres-llm-gateway\n    environment:\n      - POSTGRES_USER=postgres\n      - POSTGRES_PASSWORD=postgres\n      - POSTGRES_DB=llm_gateway\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - ./llm-gateway/pgdata:/var/lib/postgresql/data\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  llm-gateway:\n    build: ./llm-gateway\n    container_name: llm-gateway\n    env_file: ./.env\n    environment:\n      - NODE_ENV=production\n      - LOG_TO_CONSOLE=false\n      - PORT=3010\n      - BASE_PATH=/llm-gateway\n      - PGHOST=postgres\n      - PGPORT=5432\n      - PGUSER=postgres\n      - PGPASSWORD=postgres\n      - PGDATABASE=llm_gateway\n      - SPLUNK_HEC_TOKEN=${SPLUNK_HEC_TOKEN}\n      - SPLUNK_HEC_URL=${SPLUNK_HEC_URL}\n      - SPLUNK_SOURCE=llm-gateway\n      - NODE_TLS_REJECT_UNAUTHORIZED=${NODE_TLS_REJECT_UNAUTHORIZED}\n      #- SPLUNK_PASSWORD=${SPLUNK_PASSWORD}\n    expose:\n      - \"3010\"\n    ports:\n      - \"3010:3010\"\n    depends_on:\n      - postgres\n      - splunk\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  splunk:\n    image: splunk/splunk:latest\n    container_name: splunk\n    env_file: ./splunk/.env\n    environment:\n      - SPLUNK_START_ARGS=--accept-license\n      - SPLUNK_GENERAL_TERMS=--accept-sgt-current-at-splunk-com\n      # If you prefer, you can set SPLUNK_PASSWORD in .env instead of inline\n      #- SPLUNK_PASSWORD=$SPLUNK_PASSWORD\n      #- SPLUNK_PASSWORD=test\n    ports:\n      - \"7999:8000\"  # Web UI\n      - \"8088:8088\"  # HEC\n      - \"8089:8089\"  # mgmt API\n    volumes:\n      - ./splunk/var:/opt/splunk/var\n      - ./splunk/etc:/opt/splunk/etc\n      - ./splunk/hec-app:/opt/splunk/etc/apps/hec\n    networks:\n      - app-network\n    restart: unless-stopped\n  logging-orchestrator:\n    build: ./logging-orchestrator\n    container_name: logging-orchestrator\n    environment:\n      - PORT=3015\n      - BASE_PATH=/logging\n      # Optional: set a token to require Bearer auth for write endpoints\n      - ORCH_TOKEN=${ORCH_TOKEN}\n      # Seed known services (you can add more at runtime in the UI)\n      - SERVICES=[{\"name\":\"llm-gateway\",\"logging_url\":\"http://llm-gateway:3010/api/logging\"},{\"name\":\"rag\",\"logging_url\":\"http://rag-api-module:8000/admin-api/logging\"},{\"name\":\"llm-chat\",\"logging_url\":\"http://llm-chat-module:3004/admin-api/logging\"}]\n      # Optional: default HEC\n      - SPLUNK_HEC_URL=${SPLUNK_HEC_URL}\n      - SPLUNK_HEC_TOKEN=${SPLUNK_HEC_TOKEN}\n      - SPLUNK_SOURCE=platform\n      - SPLUNK_INDEX=${SPLUNK_INDEX}\n    volumes:\n      - ./logging-orchestrator/data:/data\n    ports:\n      - \"3015:3015\"\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  llm-ide-frontend:\n    build:\n      context: ./llm-ide\n      dockerfile: Dockerfile\n    container_name: llm-ide-frontend\n    ports:\n      - \"3020:3020\"\n    depends_on:\n      - llm-ide-backend\n    networks:\n      - app-network\n\n  llm-ide-backend:\n    build:\n      context: ./llm-ide/backend\n      dockerfile: Dockerfile\n    container_name: llm-ide-backend\n    ports:\n      - \"3021:3021\"\n    environment:\n      - NODE_ENV=production\n      - PORT=3021\n      - PGHOST=postgres\n      - PGPORT=5432\n      - PGUSER=postgres\n      - PGPASSWORD=postgres\n      - PGDATABASE=llm_gateway\n      - CONFIG_ENCRYPTION_KEY=${CONFIG_ENCRYPTION_KEY}\n    depends_on:\n      - postgres\n    networks:\n      - app-network\n\n\nnetworks:\n  app-network:\n    driver: bridge\n"
    }
  ]
}