{
  "version": "1.0",
  "backup": true,
  "changes": [
    {
      "id": "replace-logger-with-gateway-style",
      "description": "Replace llm-chat logger with dynamic, configurable logger similar to llm-gateway (runtime-configurable sinks, levels, sampling). Keep API compatibility exports (logs, stamp, log* funcs, redact, etc).",
      "op": "write_file",
      "path": "modular-framework/modules/llm-chat/server/logger.js",
      "mode": "overwrite",
      "content": "// modular-framework/modules/llm-chat/server/logger.js\nconst os = require('os');\n\n// ===== Defaults from ENV (backward-compatible) =====\nconst ENV_DEFAULTS = {\n  level: (process.env.LOG_LEVEL || 'info').toLowerCase(),\n  console: (process.env.LOG_TO_CONSOLE || 'false').toLowerCase() === 'true',\n  buffer_max: Number(process.env.LOG_MAX || 1000),\n  sinks: {\n    hec: {\n      enabled: !!(process.env.SPLUNK_HEC_URL && process.env.SPLUNK_HEC_TOKEN),\n      url: process.env.SPLUNK_HEC_URL || null,\n      token: process.env.SPLUNK_HEC_TOKEN || null,\n      source: process.env.SPLUNK_SOURCE || 'llm-chat',\n      index: process.env.SPLUNK_INDEX || undefined,\n      tls_verify: String(process.env.NODE_TLS_REJECT_UNAUTHORIZED || '1') !== '0',\n      timeout_ms: 3000,\n      batch_max: 100\n    }\n  },\n  fields: { service: 'llm-chat', host: os.hostname() },\n  sampling: { rate: 1.0 },\n  level_overrides: {}, // e.g. { http_access: 'info', llm: 'debug' }\n};\n\n// ===== In-memory log buffer =====\nconst logs = [];\nfunction pushBuffer(entry, cfg) {\n  logs.push(entry);\n  const max = Math.max(1, Number(cfg.buffer_max || 1000));\n  while (logs.length > max) logs.shift();\n}\n\n// ===== Utilities =====\nlet reqCounter = 0;\nfunction stamp(req, _res, next) {\n  req.id = `${Date.now().toString(36)}-${(++reqCounter).toString(36)}`;\n  next();\n}\nfunction safeStringify(v) {\n  try {\n    const seen = new WeakSet();\n    return JSON.stringify(v, (k, val) => {\n      if (typeof val === 'object' && val !== null) {\n        if (seen.has(val)) return '[Circular]';\n        seen.add(val);\n      }\n      return val;\n    });\n  } catch {\n    return '[unstringifiable]';\n  }\n}\nfunction deepMerge(a, b) {\n  if (b === null || b === undefined) return a;\n  if (Array.isArray(a) || Array.isArray(b) || typeof a !== 'object' || typeof b !== 'object') return b;\n  const out = { ...a };\n  for (const k of Object.keys(b)) out[k] = deepMerge(a[k], b[k]);\n  return out;\n}\n\n// Redaction helpers (public redact used by routes)\nfunction redactMeta(obj) {\n  if (!obj || typeof obj !== 'object') return obj;\n  const clone = JSON.parse(JSON.stringify(obj));\n  const REDACT_KEYS = ['authorization', 'Authorization', 'apiKey', 'token', 'password', 'secret'];\n  (function walk(o) {\n    if (!o || typeof o !== 'object') return;\n    for (const k of Object.keys(o)) {\n      if (REDACT_KEYS.includes(k)) o[k] = '***REDACTED***';\n      else if (typeof o[k] === 'object') walk(o[k]);\n    }\n  })(clone);\n  return clone;\n}\nfunction redact(obj) { return redactMeta(obj); }\n\n// ===== Levels & filtering =====\nconst LEVELS = ['debug', 'info', 'warn', 'error'];\nfunction levelAllows(min, lvl) {\n  const mi = LEVELS.indexOf((min || 'info').toLowerCase());\n  const li = LEVELS.indexOf((lvl || 'info').toLowerCase());\n  return li >= mi;\n}\n\n// ===== Active config (hot-reloadable) =====\nlet cfg = JSON.parse(JSON.stringify(ENV_DEFAULTS));\nfunction loadFromEnv() { return JSON.parse(JSON.stringify(ENV_DEFAULTS)); }\n\nfunction validateConfig(c) {\n  const err = (m) => { const e = new Error(m); e.status = 400; throw e; };\n  if (!c || typeof c !== 'object') err('config must be an object');\n  if (c.level && !LEVELS.includes(c.level)) err(`invalid level: ${c.level}`);\n  if (c.sampling && typeof c.sampling.rate === 'number' && (c.sampling.rate < 0 || c.sampling.rate > 1))\n    err('sampling.rate must be between 0 and 1');\n  if (c.sinks?.hec?.enabled) {\n    const { url, token } = c.sinks.hec;\n    if (!url || !token) err('hec.url and hec.token are required when hec.enabled=true');\n  }\n  return c;\n}\n\nfunction getEffectiveLoggingConfig() { return redact(cfg); }\nfunction setLoggingConfig(patch, { dryRun = false } = {}) {\n  if (patch && patch._reload) {\n    const reloaded = loadFromEnv();\n    validateConfig(reloaded);\n    if (!dryRun) cfg = reloaded;\n    return { applied: !dryRun, effective: redact(cfg) };\n    }\n  const next = validateConfig(deepMerge(cfg, patch));\n  if (dryRun) return { validated: true, next: redact(next) };\n  cfg = next; return { applied: true, effective: redact(cfg) };\n}\n\n// ===== Sinks =====\nasync function sendConsole(entry) {\n  if (!cfg.console) return;\n  const line = `[${entry.ts}] [${entry.level.toUpperCase()}] ${entry.msg} ${entry.meta ? safeStringify(entry.meta) : ''}`;\n  try {\n    if (entry.level === 'debug') console.debug(line);\n    else if (entry.level === 'info') console.info(line);\n    else if (entry.level === 'warn') console.warn(line);\n    else console.error(line);\n  } catch {}\n}\nasync function sendHec(entry) {\n  const h = cfg.sinks?.hec || {};\n  if (!h.enabled) return;\n  const payload = {\n    event: { level: entry.level, message: entry.msg, meta: entry.meta },\n    time: Math.floor(Date.now() / 1000),\n    host: cfg.fields?.host || os.hostname(),\n    sourcetype: '_json',\n    source: h.source || 'llm-chat',\n  };\n  if (h.index) payload.index = h.index;\n\n  const controller = new AbortController();\n  const timeout = setTimeout(() => controller.abort(), Number(h.timeout_ms || 3000));\n  try {\n    await fetch(h.url, {\n      method: 'POST',\n      headers: { 'Authorization': `Splunk ${h.token}`, 'Content-Type': 'application/json' },\n      body: JSON.stringify(payload),\n      signal: controller.signal\n    });\n  } finally { clearTimeout(timeout); }\n}\n\nconst sinks = [ sendConsole, sendHec ];\n\nfunction categoryLevel(min, category) {\n  const override = cfg.level_overrides?.[category];\n  return override || min;\n}\n\nfunction addLog(level, msg, meta, category) {\n  const min = categoryLevel(cfg.level, category);\n  if (!levelAllows(min, level)) return;\n  const rate = Number(cfg.sampling?.rate ?? 1);\n  if (rate < 1 && Math.random() > rate) return;\n\n  const baseMeta = { ...(meta || {}), service: cfg.fields?.service || 'llm-chat' };\n  const entry = {\n    ts: new Date().toISOString(),\n    level,\n    msg: typeof msg === 'string' ? msg : safeStringify(msg),\n    meta: redactMeta(baseMeta),\n  };\n  pushBuffer(entry, cfg);\n  for (const sink of sinks) { sink(entry).catch?.(() => {}); }\n}\n\nconst logDebug = (msg, meta, category) => addLog('debug', msg, meta, category);\nconst logInfo  = (msg, meta, category) => addLog('info',  msg, meta, category);\nconst logWarn  = (msg, meta, category) => addLog('warn',  msg, meta, category);\nconst logError = (msg, meta, category) => addLog('error', msg, meta, category);\n\n// Test hook\nasync function testLoggingSink() {\n  const probe = { ts: Date.now(), probe: true, source: 'logging_test' };\n  logInfo('logging_test', probe, 'ops');\n  return { sent: true };\n}\n\nmodule.exports = {\n  logs,\n  stamp,\n  logDebug, logInfo, logWarn, logError,\n  safeStringify,\n  getEffectiveLoggingConfig,\n  setLoggingConfig,\n  testLoggingSink,\n  redact,\n};\n"
    },
    {
      "id": "add-logging-route-admin-api",
      "description": "Add /admin-api/logging endpoints to configure logging at runtime (GET effective, PUT set config with dry_run, POST test, POST reload), similar to llm-gateway.",
      "op": "write_file",
      "path": "modular-framework/modules/llm-chat/server/routes/logging.js",
      "mode": "create_if_missing",
      "content": "// modular-framework/modules/llm-chat/server/routes/logging.js\nconst express = require('express');\nconst router = express.Router();\nconst {\n  getEffectiveLoggingConfig,\n  setLoggingConfig,\n  testLoggingSink,\n} = require('../logger');\n\n// Simple optional bearer auth for internal calls\nfunction requireInternalAuth(req, res, next) {\n  const token = process.env.INTERNAL_API_TOKEN;\n  if (!token) return next(); // dev-friendly default; set INTERNAL_API_TOKEN to enforce\n  const hdr = req.headers['authorization'] || '';\n  if (hdr === `Bearer ${token}`) return next();\n  return res.status(401).json({ error: 'unauthorized' });\n}\n\nrouter.get('/logging', requireInternalAuth, (_req, res) => {\n  res.json({ effective: getEffectiveLoggingConfig(), redacted: true });\n});\n\nrouter.put('/logging', requireInternalAuth, (req, res) => {\n  const dry = String(req.query.dry_run || '').toLowerCase() === '1';\n  try {\n    const result = setLoggingConfig(req.body || {}, { dryRun: dry });\n    res.json({ ok: true, dry_run: dry, result });\n  } catch (e) {\n    res.status(400).json({ ok: false, error: e.message || 'invalid config' });\n  }\n});\n\nrouter.post('/logging/test', requireInternalAuth, async (_req, res) => {\n  try {\n    const r = await testLoggingSink();\n    res.json({ ok: true, result: r });\n  } catch (e) {\n    res.status(500).json({ ok: false, error: e.message || 'test failed' });\n  }\n});\n\nrouter.post('/logging/reload', requireInternalAuth, (_req, res) => {\n  try {\n    const result = setLoggingConfig({ _reload: true }, { dryRun: false });\n    res.json({ ok: true, result });\n  } catch (e) {\n    res.status(500).json({ ok: false, error: e.message || 'reload failed' });\n  }\n});\n\nmodule.exports = { router };\n"
    },
    {
      "id": "mount-admin-logging-routes",
      "description": "Mount logging router under /admin-api and BASE_PATH/admin-api in llm-chat app.js.",
      "op": "patch_text",
      "path": "modular-framework/modules/llm-chat/server/app.js",
      "patches": [
        {
          "type": "insert_after",
          "anchor": "const { router: agentRouter } = require('./routes/agent');",
          "replacement": "const { router: loggingRouter } = require('./routes/logging');\n"
        },
        {
          "type": "insert_after",
          "anchor": "// basic routes",
          "replacement": "// admin logging API (for logging orchestrator)\napp.use('/admin-api', loggingRouter);\nif (BASE_PATH) app.use(`${BASE_PATH}/admin-api`, loggingRouter);\n\n"
        }
      ]
    },
    {
      "id": "delete-legacy-splunk-logger-dir",
      "description": "Remove old splunk-logger helper module from llm-chat (replaced by dynamic HEC sink built-in).",
      "op": "delete_path",
      "path": "modular-framework/modules/llm-chat/splunk-logger",
      "recursive": true,
      "if_absent": "skip"
    },
    {
      "id": "delete-legacy-server-js",
      "description": "Remove legacy server.js (duplicate server entrypoint with old logging). app/index.js is the canonical entry.",
      "op": "delete_path",
      "path": "modular-framework/modules/llm-chat/server.js",
      "recursive": false,
      "if_absent": "skip"
    },
    {
      "id": "clean-dockerfile-copy-splunk",
      "description": "Remove COPY of splunk-logger from Dockerfile for llm-chat.",
      "op": "patch_text",
      "path": "modular-framework/modules/llm-chat/Dockerfile",
      "patches": [
        {
          "type": "replace_regex",
          "match": "^COPY \\./splunk-logger.*\\n",
          "replacement": ""
        }
      ]
    },
    {
      "id": "ensure-app-http-access-logging-category",
      "description": "No changes needed: http access logging already exists. Keep for parity.",
      "op": "patch_text",
      "path": "modular-framework/modules/llm-chat/server/app.js",
      "patches": [
        {
          "type": "ensure_line",
          "match": "app.use((req, res, next) => {",
          "newline": true
        }
      ]
    },
    {
      "id": "compatibility-ensure-redact-export",
      "description": "Ensure routes that import redact still work with the new logger (already exporting redact). No code change here if imports are fine.",
      "op": "patch_text",
      "path": "modular-framework/modules/llm-chat/server/routes/chat.js",
      "patches": [
        {
          "type": "ensure_line",
          "match": "const { logInfo, logWarn, logError, logDebug, redact } = require('../logger');",
          "newline": true
        }
      ]
    }
  ]
}