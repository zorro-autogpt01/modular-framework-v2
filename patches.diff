diff --git a/modular-framework/modules/llm-tester/src/routes/admin.js b/modular-framework/modules/llm-tester/src/routes/admin.js
index 1c2b3d4..5e6f7a8 100644
--- a/modular-framework/modules/llm-tester/src/routes/admin.js
+++ b/modular-framework/modules/llm-tester/src/routes/admin.js
@@ -1,37 +1,90 @@
 import { Router } from "express";
 import { Storage } from "../storage.js";
+import { chatCompletion } from "../llm.js";
+import { retrieve } from "../rag.js";
 
-import { logInfo, logWarn } from "../logger.js";
+import { logInfo, logWarn, logError } from "../logger.js";
 
 const router = Router();
 
 router.post("/webhooks", (req, res) => {
-  const rid = req.id; logInfo('LT admin webhook create <-', { rid, ip: req.ip, body: { event, url: url ? url.toString() : null } });
-
-  const { event, url, secret } = req.body || {};
+  const rid = req.id;
+  const { event, url, secret } = req.body || {};
+  logInfo('LT admin webhook create <-', { rid, ip: req.ip, body: { event, url: url ? url.toString() : null } });
   if (!event || !url) return res.status(400).json({ error: "event_and_url_required" });
   const hook = Storage.addWebhook({ event, url, secret });
   logInfo('LT admin webhook create ->', { rid, id: hook.id });
 
   res.json({ ok: true, id: hook.id });
 });
 
 // Config (RAG + Chat Replay)
 router.get("/config", (req, res) => {
   const rid = req.id; logInfo('LT admin config get', { rid, ip: req.ip });
   res.json(Storage.getConfig());
 });
 
 router.put("/config", (req, res) => {
   const rid = req.id; const { ragEnabled, chatReplayEnabled } = req.body || {};
   logInfo('LT admin config put <-', { rid, ip: req.ip, ragEnabled, chatReplayEnabled });
   if (ragEnabled != null && typeof ragEnabled !== "boolean")
     return res.status(400).json({ error: "invalid_value", message: "ragEnabled must be boolean" });
   if (chatReplayEnabled != null && typeof chatReplayEnabled !== "boolean")
     return res.status(400).json({ error: "invalid_value", message: "chatReplayEnabled must be boolean" });
   const saved = Storage.saveConfig({ ragEnabled, chatReplayEnabled });
   logInfo('LT admin config put ->', { rid, saved });
   res.json({ ok: true, config: saved });
 });
 
+// Connectivity checks for LLM Gateway and RAG
+router.get("/connectivity", async (req, res) => {
+  const rid = req.id;
+  logInfo('LT admin connectivity check <-', { rid, ip: req.ip });
+
+  const gatewayBase = req.query.gatewayBase || "/llm-gateway/api";
+  const model = req.query.model || "gpt-4o-mini";
+  const ragTopK = Number(req.query.ragTopK || 1);
+
+  const result = { gateway: {}, rag: {} };
+
+  // Gateway check via minimal chat completion
+  const gStart = Date.now();
+  try {
+    const r = await chatCompletion({
+      baseUrl: gatewayBase,
+      model,
+      messages: [{ role: "user", content: "ping" }],
+      headers: {}
+    });
+    result.gateway.ok = true;
+    result.gateway.tookMs = Date.now() - gStart;
+    result.gateway.contentPreview = (r.content || "").slice(0, 200);
+  } catch (e) {
+    result.gateway.ok = false;
+    result.gateway.tookMs = Date.now() - gStart;
+    result.gateway.error = e.message || String(e);
+    logWarn('LT admin connectivity gateway failed', { rid, error: result.gateway.error });
+  }
+
+  // RAG check via minimal retrieve
+  const rStart = Date.now();
+  try {
+    const text = await retrieve({ question: "ping", top_k: ragTopK });
+    result.rag.ok = true;
+    result.rag.tookMs = Date.now() - rStart;
+    result.rag.snippetLength = (text || "").length;
+    result.rag.preview = (text || "").slice(0, 200);
+  } catch (e) {
+    result.rag.ok = false;
+    result.rag.tookMs = Date.now() - rStart;
+    result.rag.error = e.message || String(e);
+    logWarn('LT admin connectivity rag failed', { rid, error: result.rag.error });
+  }
+
+  const ok = !!(result.gateway.ok && result.rag.ok);
+  logInfo('LT admin connectivity check ->', { rid, ok, gateway: result.gateway, rag: result.rag });
+  res.json({ ok, ...result });
+});
+
 export default router;
diff --git a/modular-framework/modules/llm-tester/src/routes/tests.js b/modular-framework/modules/llm-tester/src/routes/tests.js
index a1b2c3d..b4c5d6e 100644
--- a/modular-framework/modules/llm-tester/src/routes/tests.js
+++ b/modular-framework/modules/llm-tester/src/routes/tests.js
@@ -1,232 +1,259 @@
 import { Router } from "express";
 import { Storage } from "../storage.js";
 import { chatCompletion } from "../llm.js";
 import { getFile } from "../github.js";
 import { retrieve } from "../rag.js";
 import { openSSE, send, close } from "../sse.js";
 import { buildMessages, assertAll } from "../util.js";
 import { notifyWebhooks } from "../webhook.js";
 import { randomUUID } from "node:crypto";
-import { logWarn } from "../logger.js";
+import { logWarn, logInfo } from "../logger.js";
 
 const router = Router();
 
 router.get("/", (req, res) => {
   const { suite, tag, limit } = req.query;
   const items = Storage.listTests({
     suite,
     tag,
     limit: limit ? parseInt(limit, 10) : undefined
   });
   res.json({ items });
 });
 
 router.post("/", (req, res) => {
   const t = req.body || {};
   if (!t.name || !t.suite || !t.kind) return res.status(400).json({ error: "name, suite, kind required" });
   const saved = Storage.saveTest(t);
   res.json({ ok: true, testId: saved.id, version: saved.version });
 });
 
 router.get("/:id", (req, res) => {
   const t = Storage.getTest(req.params.id);
   if (!t) return res.status(404).json({ error: "not_found" });
   res.json(t);
 });
 
 router.put("/:id", (req, res) => {
   const existing = Storage.getTest(req.params.id);
   if (!existing) return res.status(404).json({ error: "not_found" });
   const saved = Storage.saveTest({ ...existing, ...req.body, id: existing.id });
   res.json({ ok: true, testId: saved.id, version: saved.version });
 });
 
 router.post("/:id/execute", async (req, res) => {
   const test = Storage.getTest(req.params.id);
   if (!test) return res.status(404).json({ error: "not_found" });
+  const rid = req.id;
 
   const doStream = String(req.query.stream || "").toLowerCase() === "true" || req.headers.accept?.includes("text/event-stream");
   let startedAt = new Date().toISOString();
 
   if (doStream) openSSE(res), send(res, { type: "phase", phase: "prepare" });
 
   try {
     // Artifact (tolerant)
     let artifactContent = "";
     if (test.input?.artifact?.path) {
       try {
         if (doStream) send(res, { type: "artifact", path: test.input.artifact.path });
         artifactContent = await getFile(test.input.artifact);
       } catch (e) {
         logWarn("Artifact fetch failed, continuing without it", { path: test.input.artifact.path, error: e.message }, "artifact");
         if (test.input.artifact.fallback) {
           artifactContent = String(test.input.artifact.fallback);
           logWarn("Using fallback content for missing artifact", { path: test.input.artifact.path, len: artifactContent.length }, "artifact");
         } else if (test.input.artifact.optional) {
           artifactContent = "";
         } else {
           artifactContent = "Placeholder: CHANGELOG not available.";
           logWarn("Using placeholder for missing artifact", { path: test.input.artifact.path }, "artifact");
         }
       }
     }
 
     // RAG gate (global + per-test)
     const cfg = Storage.getConfig();
     const ragRequested = !!test.context?.ragQuery?.question;
     const ragDisabledPerTest = test.context?.disableRag === true;
     const canUseRag = cfg.ragEnabled && ragRequested && !ragDisabledPerTest;
 
     let ragContext = "";
     if (canUseRag) {
       if (doStream) send(res, { type: "rag", status: "retrieving" });
       try {
-        ragContext = await retrieve({ question: test.context.ragQuery.question, top_k: 4 });
+        logInfo("RAG request", { rid, question: test.context.ragQuery.question, top_k: 4 }, "rag");
+        ragContext = await retrieve({ question: test.context.ragQuery.question, top_k: 4 });
+        logInfo("RAG response", { rid, length: (ragContext || "").length, content: ragContext }, "rag");
       } catch (e) {
         logWarn("RAG retrieve failed, continuing without RAG", { error: e.message }, "rag");
       }
     } else {
       if (doStream) send(res, { type: "rag", status: "skipped", reason: !cfg.ragEnabled ? "global_disabled" : (ragDisabledPerTest ? "test_disabled" : "not_requested") });
     }
     const ragUsed = Boolean(canUseRag && ragContext);
 
     const messages = buildMessages(test.input?.messages, {
       artifactContent,
       ragContext,
       staticContext: test.context?.static
     });
 
+    logInfo("LLM Gateway request", {
+      rid,
+      baseUrl: test.llmGateway?.baseUrl || "/llm-gateway/api",
+      model: test.llmGateway?.model,
+      messages
+    }, "llm");
+
     if (doStream) send(res, { type: "llm", model: test.llmGateway?.model || "unknown" });
 
     const t0 = Date.now();
     const { content } = await chatCompletion({
       baseUrl: test.llmGateway?.baseUrl || "/llm-gateway/api",
       headers: test.llmGateway?.headers || {},
       model: test.llmGateway?.model,
       messages,
       stream: false
     });
     const latencyMs = Date.now() - t0;
 
+    logInfo("LLM Gateway response", { rid, model: test.llmGateway?.model, content }, "llm");
+
     const { ok: baseOk, results } = assertAll({ completion: content, test });
 
     let judgeExplanations = [];
     if (test.assert?.semantic?.criteria?.length) {
       const j = test.assert.semantic;
       const judgePrompt = [
         { role: "system", content: `You are a strict evaluator. Rubric:\n${j.rubric || ""}\nReturn JSON exactly: {"scores":[{"criterion":"","score":0..1,"why":""},...]}` },
         { role: "user", content: `Candidate output:\n${content}\n\nNow evaluate.` }
       ];
-      const { content: judgeOut } = await chatCompletion({
+      logInfo("LLM Judge request", {
+        rid,
+        baseUrl: j.judge.baseUrl || test.llmGateway?.baseUrl || "/llm-gateway/api",
+        model: j.judge.model || test.llmGateway?.model,
+        messages: judgePrompt
+      }, "llm");
+      const { content: judgeOut } = await chatCompletion({
         baseUrl: j.judge.baseUrl || test.llmGateway?.baseUrl || "/llm-gateway/api",
         headers: j.judge.headers || test.llmGateway?.headers || {},
         model: j.judge.model || test.llmGateway?.model,
         messages: judgePrompt
       });
+      logInfo("LLM Judge response", { rid, model: j.judge.model || test.llmGateway?.model, content: judgeOut }, "llm");
       let parsed = {};
       try { parsed = JSON.parse(judgeOut); } catch { parsed = {}; }
       const scores = parsed?.scores || [];
       for (const c of (j.criteria || [])) {
         const got = scores.find(s => (s.criterion || "").toLowerCase().includes(c.name.toLowerCase()));
         const score = got?.score ?? 0;
         const pass = score >= c.minScore;
         results.push({ name: `semantic:${c.name}`, ok: pass, score, why: got?.why });
         if (got?.why) judgeExplanations.push({ criterion: c.name, why: got.why });
       }
     }
 
     const ok = results.every(r => r.ok);
     const run = {
       runId: "run_" + randomUUID(),
       testId: test.id,
       suite: test.suite,
       ok,
       startedAt,
       endedAt: new Date().toISOString(),
       latencyMs,
       assertions: results,
       artifacts: {
         prompt: messages,
         completion: content,
         judgeExplanations,
         ragUsed,
         llmGateway: test.llmGateway || null
       }
     };
 
     Storage.saveRun(run);
     await notifyWebhooks(Storage.listWebhooks(), ok ? "run.finished" : "run.failed", run);
 
     if (doStream) {
       send(res, { type: "assertions", results });
       send(res, { type: "done", ok, latencyMs, runId: run.runId });
       return close(res);
     } else {
       return res.json(run);
     }
   } catch (e) {
     if (doStream) {
       send(res, { type: "error", message: e.message || String(e) });
       return close(res);
     }
     return res.status(500).json({ error: "execute_failed", message: e.message || String(e) });
   }
 });
 
 router.get("/:id/replay", async (req, res) => {
   const test = Storage.getTest(req.params.id);
   if (!test) return res.status(404).json({ error: "not_found" });
 
   // Artifact
   let artifactContent = "";
   if (test.input?.artifact?.path) {
     try {
       artifactContent = await getFile(test.input.artifact);
     } catch {
       artifactContent = test.input?.artifact?.fallback || (test.input?.artifact?.optional ? "" : "Placeholder: artifact unavailable.");
     }
   }
 
   // RAG
   const cfg = Storage.getConfig();
   const ragRequested = !!test.context?.ragQuery?.question;
   const ragDisabledPerTest = test.context?.disableRag === true;
 
   const mode = (req.query.includeRag || "auto").toString();
   const allowAuto = cfg.ragEnabled && ragRequested && !ragDisabledPerTest;
   const includeRag =
     mode === "true" ? true :
     mode === "false" ? false :
     allowAuto;
 
   let ragContext = "";
   if (includeRag) {
-    try { ragContext = await retrieve({ question: test.context.ragQuery.question, top_k: 4 }); } catch {}
+    try {
+      logInfo("RAG request", { rid: req.id, question: test.context.ragQuery.question, top_k: 4 }, "rag");
+      ragContext = await retrieve({ question: test.context.ragQuery.question, top_k: 4 });
+      logInfo("RAG response", { rid: req.id, length: (ragContext || "").length, content: ragContext }, "rag");
+    } catch {}
   }
 
   const messages = buildMessages(test.input?.messages, {
     artifactContent,
     ragContext,
     staticContext: test.context?.static
   });
 
   const payload = {
     provider: "openai-compatible",
     baseUrl: "/llm-gateway/api",
     model: test.llmGateway?.model || "gpt-4o-mini",
     messages
   };
 
   res.json({
     ok: true,
     replay: payload,
     info: {
       ragIncluded: includeRag && !!ragContext,
       ragGloballyEnabled: cfg.ragEnabled === true,
       ragRequested,
       ragDisabledPerTest
     }
   });
 });
 
 export default router;
diff --git a/modular-framework/modules/llm-tester/server.js b/modular-framework/modules/llm-tester/server.js
index 13579bd..2468ace 100644
--- a/modular-framework/modules/llm-tester/server.js
+++ b/modular-framework/modules/llm-tester/server.js
@@ -11,7 +11,7 @@ import ciRouter from "./src/routes/ci.js";
 import adminRouter from "./src/routes/admin.js";
 import loggingRouter from "./src/routes/logging.js";
 import logsRouter from "./src/routes/logs.js";
-import { stamp, logInfo } from "./src/logger.js";
+import { stamp, logInfo, logError } from "./src/logger.js";
 
 const app = express();
 app.disable("x-powered-by");